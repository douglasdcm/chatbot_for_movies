{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A intenção do projeto é criar um chatbot baseado em reviews de filmes para que se possa fazer perguntas e manter uma conversa livre\n",
    "\n",
    "- link do banco de dados https://www.kaggle.com/Cornell-University/movie-dialog-corpus?select=movie_lines.tsv\n",
    "- referências\n",
    ">- https://shanebarker.com/blog/deep-learning-chatbot/\n",
    "> -https://towardsdatascience.com/how-to-create-a-chatbot-with-python-deep-learning-in-less-than-an-hour-56a063bdfc44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /home/douglas/.local/lib/python3.8/site-packages (3.8.3)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/douglas/.local/lib/python3.8/site-packages (from gensim) (1.5.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/douglas/.local/lib/python3.8/site-packages (from gensim) (3.0.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/douglas/.local/lib/python3.8/site-packages (from gensim) (1.18.5)\n",
      "Requirement already satisfied: six>=1.5.0 in /home/douglas/.local/lib/python3.8/site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from smart-open>=1.8.1->gensim) (2.22.0)\n",
      "Requirement already satisfied: tensorflow in /home/douglas/.local/lib/python3.8/site-packages (2.3.1)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /home/douglas/.local/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /home/douglas/.local/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /home/douglas/.local/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/douglas/.local/lib/python3.8/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /home/douglas/.local/lib/python3.8/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/douglas/.local/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/douglas/.local/lib/python3.8/site-packages (from tensorflow) (0.10.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /home/douglas/.local/lib/python3.8/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/douglas/.local/lib/python3.8/site-packages (from tensorflow) (1.33.1)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /home/douglas/.local/lib/python3.8/site-packages (from tensorflow) (1.18.5)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /home/douglas/.local/lib/python3.8/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/douglas/.local/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/douglas/.local/lib/python3.8/site-packages (from tensorflow) (0.35.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/douglas/.local/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /home/douglas/.local/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/douglas/.local/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from protobuf>=3.9.2->tensorflow) (45.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/douglas/.local/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/douglas/.local/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/douglas/.local/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.22.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/douglas/.local/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/douglas/.local/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /home/douglas/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/douglas/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/douglas/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: keras in /home/douglas/.local/lib/python3.8/site-packages (2.4.3)\n",
      "Requirement already satisfied: h5py in /home/douglas/.local/lib/python3.8/site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/douglas/.local/lib/python3.8/site-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/douglas/.local/lib/python3.8/site-packages (from keras) (1.5.2)\n",
      "Requirement already satisfied: six in /home/douglas/.local/lib/python3.8/site-packages (from h5py->keras) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install gensim\n",
    "!pip3 install tensorflow\n",
    "!pip3 install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import gensim\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.models import Sequential\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening movie reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = pd.read_csv('./chatdata/movie_lines.tsv', header = None, delimiter=\"\\t\", quoting=3, encoding='ISO-8859-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1045</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>They do not!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1044</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>They do to!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L985</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I hope so.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L984</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>She okay?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L925</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Let's go.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>L924</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>Wow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>L872</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Okay -- you're gonna need to learn how to lie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>L871</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"L870</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I'm kidding.  You know how sometimes you just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>L869</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Like my fear of wearing pastels?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0   1   2        3                                                  4\n",
       "0  L1045  u0  m0   BIANCA                                       They do not!\n",
       "1  L1044  u2  m0  CAMERON                                        They do to!\n",
       "2   L985  u0  m0   BIANCA                                         I hope so.\n",
       "3   L984  u2  m0  CAMERON                                          She okay?\n",
       "4   L925  u0  m0   BIANCA                                          Let's go.\n",
       "5   L924  u2  m0  CAMERON                                                Wow\n",
       "6   L872  u0  m0   BIANCA     Okay -- you're gonna need to learn how to lie.\n",
       "7   L871  u2  m0  CAMERON                                                 No\n",
       "8  \"L870  u0  m0   BIANCA  I'm kidding.  You know how sometimes you just ...\n",
       "9   L869  u0  m0   BIANCA                   Like my fear of wearing pastels?"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the index of the conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.columns = ['msg_line', 'user1_id', 'movie_id', 'user_name', 'msg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_char(txt):\n",
    "    return re.sub('[^0-9]','', txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['msg_line_clean'] = [remove_char(msg) for msg in messages['msg_line']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg_line</th>\n",
       "      <th>user1_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>msg</th>\n",
       "      <th>msg_line_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1045</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>They do not!</td>\n",
       "      <td>1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1044</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>They do to!</td>\n",
       "      <td>1044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L985</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I hope so.</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L984</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>She okay?</td>\n",
       "      <td>984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L925</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Let's go.</td>\n",
       "      <td>925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>L924</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>Wow</td>\n",
       "      <td>924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>L872</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Okay -- you're gonna need to learn how to lie.</td>\n",
       "      <td>872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>L871</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>No</td>\n",
       "      <td>871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"L870</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I'm kidding.  You know how sometimes you just ...</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>L869</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Like my fear of wearing pastels?</td>\n",
       "      <td>869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  msg_line user1_id movie_id user_name  \\\n",
       "0    L1045       u0       m0    BIANCA   \n",
       "1    L1044       u2       m0   CAMERON   \n",
       "2     L985       u0       m0    BIANCA   \n",
       "3     L984       u2       m0   CAMERON   \n",
       "4     L925       u0       m0    BIANCA   \n",
       "5     L924       u2       m0   CAMERON   \n",
       "6     L872       u0       m0    BIANCA   \n",
       "7     L871       u2       m0   CAMERON   \n",
       "8    \"L870       u0       m0    BIANCA   \n",
       "9     L869       u0       m0    BIANCA   \n",
       "\n",
       "                                                 msg msg_line_clean  \n",
       "0                                       They do not!           1045  \n",
       "1                                        They do to!           1044  \n",
       "2                                         I hope so.            985  \n",
       "3                                          She okay?            984  \n",
       "4                                          Let's go.            925  \n",
       "5                                                Wow            924  \n",
       "6     Okay -- you're gonna need to learn how to lie.            872  \n",
       "7                                                 No            871  \n",
       "8  I'm kidding.  You know how sometimes you just ...            870  \n",
       "9                   Like my fear of wearing pastels?            869  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['msg_line_clean'] = pd.to_numeric(messages['msg_line_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = messages.set_index('msg_line_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg_line</th>\n",
       "      <th>user1_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>msg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>msg_line_clean</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>L1045</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>They do not!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>L1044</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>They do to!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>L985</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I hope so.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>L984</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>She okay?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>L925</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Let's go.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>L924</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>Wow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>L872</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Okay -- you're gonna need to learn how to lie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>L871</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>\"L870</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I'm kidding.  You know how sometimes you just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>L869</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Like my fear of wearing pastels?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               msg_line user1_id movie_id user_name  \\\n",
       "msg_line_clean                                        \n",
       "1045              L1045       u0       m0    BIANCA   \n",
       "1044              L1044       u2       m0   CAMERON   \n",
       "985                L985       u0       m0    BIANCA   \n",
       "984                L984       u2       m0   CAMERON   \n",
       "925                L925       u0       m0    BIANCA   \n",
       "924                L924       u2       m0   CAMERON   \n",
       "872                L872       u0       m0    BIANCA   \n",
       "871                L871       u2       m0   CAMERON   \n",
       "870               \"L870       u0       m0    BIANCA   \n",
       "869                L869       u0       m0    BIANCA   \n",
       "\n",
       "                                                              msg  \n",
       "msg_line_clean                                                     \n",
       "1045                                                 They do not!  \n",
       "1044                                                  They do to!  \n",
       "985                                                    I hope so.  \n",
       "984                                                     She okay?  \n",
       "925                                                     Let's go.  \n",
       "924                                                           Wow  \n",
       "872                Okay -- you're gonna need to learn how to lie.  \n",
       "871                                                            No  \n",
       "870             I'm kidding.  You know how sometimes you just ...  \n",
       "869                              Like my fear of wearing pastels?  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening conversation sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_seq = pd.read_csv('./chatdata/movie_conversations.tsv', header = None, delimiter=\"\\t\", quoting=3, encoding='ISO-8859-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L194' 'L195' 'L196' 'L197']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L198' 'L199']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L200' 'L201' 'L202' 'L203']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L204' 'L205' 'L206']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L207' 'L208']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L271' 'L272' 'L273' 'L274' 'L275']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L276' 'L277']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L280' 'L281']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L363' 'L364']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L365' 'L366']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2                                     3\n",
       "0  u0  u2  m0         ['L194' 'L195' 'L196' 'L197']\n",
       "1  u0  u2  m0                       ['L198' 'L199']\n",
       "2  u0  u2  m0         ['L200' 'L201' 'L202' 'L203']\n",
       "3  u0  u2  m0                ['L204' 'L205' 'L206']\n",
       "4  u0  u2  m0                       ['L207' 'L208']\n",
       "5  u0  u2  m0  ['L271' 'L272' 'L273' 'L274' 'L275']\n",
       "6  u0  u2  m0                       ['L276' 'L277']\n",
       "7  u0  u2  m0                       ['L280' 'L281']\n",
       "8  u0  u2  m0                       ['L363' 'L364']\n",
       "9  u0  u2  m0                       ['L365' 'L366']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_seq.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_seq.columns = ['user1_id', 'user2_id', 'movie_id', 'sequence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user1_id</th>\n",
       "      <th>user2_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L194' 'L195' 'L196' 'L197']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L198' 'L199']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L200' 'L201' 'L202' 'L203']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L204' 'L205' 'L206']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L207' 'L208']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L271' 'L272' 'L273' 'L274' 'L275']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L276' 'L277']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L280' 'L281']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L363' 'L364']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L365' 'L366']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user1_id user2_id movie_id                              sequence\n",
       "0       u0       u2       m0         ['L194' 'L195' 'L196' 'L197']\n",
       "1       u0       u2       m0                       ['L198' 'L199']\n",
       "2       u0       u2       m0         ['L200' 'L201' 'L202' 'L203']\n",
       "3       u0       u2       m0                ['L204' 'L205' 'L206']\n",
       "4       u0       u2       m0                       ['L207' 'L208']\n",
       "5       u0       u2       m0  ['L271' 'L272' 'L273' 'L274' 'L275']\n",
       "6       u0       u2       m0                       ['L276' 'L277']\n",
       "7       u0       u2       m0                       ['L280' 'L281']\n",
       "8       u0       u2       m0                       ['L363' 'L364']\n",
       "9       u0       u2       m0                       ['L365' 'L366']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_seq.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_conversation(txt):\n",
    "    txt_alt = txt.split(' ')\n",
    "    return txt_alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_to_list(seq):\n",
    "    seq_list = [remove_char(s) for s in seq]\n",
    "    return seq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['msg_2'] = '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_conversations(seq_list, df, filter1, filter2):\n",
    "    i = 0\n",
    "    while i in range(len(seq_list)):\n",
    "        if i+1 < len(seq_list):\n",
    "            next_msg = df.loc[int(seq_list[i+1]), filter1]\n",
    "            #print(str(i))\n",
    "            #print(next_msg)\n",
    "            #print(seq_list[i])\n",
    "            df.at[int(seq_list[i]), filter2] = next_msg\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_conversations(['194', '195', '196', '197'], messages, 'msg', 'msg_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Well I thought we'd start with pronunciation if that's okay with you.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.loc[195, 'msg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for conv in conv_seq['sequence']:\n",
    "    #print(conv)\n",
    "    seq = split_conversation(conv)\n",
    "    #print(seq)\n",
    "    #txt_alt = remove_char(txt_alt)      \n",
    "    txt_alt = [remove_char(s) for s in seq]\n",
    "    #print(txt_alt)\n",
    "    link_conversations(txt_alt, messages, 'msg', 'msg_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Well I thought we'd start with pronunciation if that's okay with you.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.loc[194, 'msg_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg_line</th>\n",
       "      <th>user1_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>msg</th>\n",
       "      <th>msg_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>msg_line_clean</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>L1045</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>They do not!</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>L1044</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>They do to!</td>\n",
       "      <td>They do not!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>L985</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I hope so.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>L984</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>She okay?</td>\n",
       "      <td>I hope so.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>L925</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Let's go.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>L924</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>Wow</td>\n",
       "      <td>Let's go.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>L872</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Okay -- you're gonna need to learn how to lie.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>L871</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>No</td>\n",
       "      <td>Okay -- you're gonna need to learn how to lie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>\"L870</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I'm kidding.  You know how sometimes you just ...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>L869</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Like my fear of wearing pastels?</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>\"L868</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>The \"\"real you\"\".\"</td>\n",
       "      <td>Like my fear of wearing pastels?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>L867</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>What good stuff?</td>\n",
       "      <td>The \"\"real you\"\".\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>L866</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>I figured you'd get to the good stuff eventually.</td>\n",
       "      <td>What good stuff?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>L865</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>Thank God!  If I had to hear one more story ab...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>L864</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Me.  This endless ...blonde babble. I'm like b...</td>\n",
       "      <td>Thank God!  If I had to hear one more story ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>L863</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>What crap?</td>\n",
       "      <td>Me.  This endless ...blonde babble. I'm like b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>L862</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>do you listen to this crap?</td>\n",
       "      <td>What crap?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>L861</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>No...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>\"L860</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Then Guillermo says \"\"If you go any lighter yo...</td>\n",
       "      <td>No...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>L699</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>You always been this selfish?</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>L698</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>But</td>\n",
       "      <td>You always been this selfish?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>L697</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>Then that's all you had to say.</td>\n",
       "      <td>But</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>L696</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Well no...</td>\n",
       "      <td>Then that's all you had to say.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>L695</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>You never wanted to go out with 'me did you?</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>L694</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I was?</td>\n",
       "      <td>You never wanted to go out with 'me did you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>\"L693</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>I looked for you back at the party but you alw...</td>\n",
       "      <td>I was?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>L663</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Tons</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>L662</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>Have fun tonight?</td>\n",
       "      <td>Tons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>L578</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>I believe we share an art instructor</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>L577</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>You know Chastity?</td>\n",
       "      <td>I believe we share an art instructor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               msg_line user1_id movie_id user_name  \\\n",
       "msg_line_clean                                        \n",
       "1045              L1045       u0       m0    BIANCA   \n",
       "1044              L1044       u2       m0   CAMERON   \n",
       "985                L985       u0       m0    BIANCA   \n",
       "984                L984       u2       m0   CAMERON   \n",
       "925                L925       u0       m0    BIANCA   \n",
       "924                L924       u2       m0   CAMERON   \n",
       "872                L872       u0       m0    BIANCA   \n",
       "871                L871       u2       m0   CAMERON   \n",
       "870               \"L870       u0       m0    BIANCA   \n",
       "869                L869       u0       m0    BIANCA   \n",
       "868               \"L868       u2       m0   CAMERON   \n",
       "867                L867       u0       m0    BIANCA   \n",
       "866                L866       u2       m0   CAMERON   \n",
       "865                L865       u2       m0   CAMERON   \n",
       "864                L864       u0       m0    BIANCA   \n",
       "863                L863       u2       m0   CAMERON   \n",
       "862                L862       u0       m0    BIANCA   \n",
       "861                L861       u2       m0   CAMERON   \n",
       "860               \"L860       u0       m0    BIANCA   \n",
       "699                L699       u2       m0   CAMERON   \n",
       "698                L698       u0       m0    BIANCA   \n",
       "697                L697       u2       m0   CAMERON   \n",
       "696                L696       u0       m0    BIANCA   \n",
       "695                L695       u2       m0   CAMERON   \n",
       "694                L694       u0       m0    BIANCA   \n",
       "693               \"L693       u2       m0   CAMERON   \n",
       "663                L663       u0       m0    BIANCA   \n",
       "662                L662       u2       m0   CAMERON   \n",
       "578                L578       u2       m0   CAMERON   \n",
       "577                L577       u0       m0    BIANCA   \n",
       "\n",
       "                                                              msg  \\\n",
       "msg_line_clean                                                      \n",
       "1045                                                 They do not!   \n",
       "1044                                                  They do to!   \n",
       "985                                                    I hope so.   \n",
       "984                                                     She okay?   \n",
       "925                                                     Let's go.   \n",
       "924                                                           Wow   \n",
       "872                Okay -- you're gonna need to learn how to lie.   \n",
       "871                                                            No   \n",
       "870             I'm kidding.  You know how sometimes you just ...   \n",
       "869                              Like my fear of wearing pastels?   \n",
       "868                                            The \"\"real you\"\".\"   \n",
       "867                                              What good stuff?   \n",
       "866             I figured you'd get to the good stuff eventually.   \n",
       "865             Thank God!  If I had to hear one more story ab...   \n",
       "864             Me.  This endless ...blonde babble. I'm like b...   \n",
       "863                                                    What crap?   \n",
       "862                                   do you listen to this crap?   \n",
       "861                                                         No...   \n",
       "860             Then Guillermo says \"\"If you go any lighter yo...   \n",
       "699                                 You always been this selfish?   \n",
       "698                                                           But   \n",
       "697                               Then that's all you had to say.   \n",
       "696                                                    Well no...   \n",
       "695                  You never wanted to go out with 'me did you?   \n",
       "694                                                        I was?   \n",
       "693             I looked for you back at the party but you alw...   \n",
       "663                                                          Tons   \n",
       "662                                             Have fun tonight?   \n",
       "578                          I believe we share an art instructor   \n",
       "577                                            You know Chastity?   \n",
       "\n",
       "                                                            msg_2  \n",
       "msg_line_clean                                                     \n",
       "1045                                                            -  \n",
       "1044                                                 They do not!  \n",
       "985                                                             -  \n",
       "984                                                    I hope so.  \n",
       "925                                                             -  \n",
       "924                                                     Let's go.  \n",
       "872                                                             -  \n",
       "871                Okay -- you're gonna need to learn how to lie.  \n",
       "870                                                            No  \n",
       "869                                                             -  \n",
       "868                              Like my fear of wearing pastels?  \n",
       "867                                            The \"\"real you\"\".\"  \n",
       "866                                              What good stuff?  \n",
       "865                                                             -  \n",
       "864             Thank God!  If I had to hear one more story ab...  \n",
       "863             Me.  This endless ...blonde babble. I'm like b...  \n",
       "862                                                    What crap?  \n",
       "861                                                             -  \n",
       "860                                                         No...  \n",
       "699                                                             -  \n",
       "698                                 You always been this selfish?  \n",
       "697                                                           But  \n",
       "696                               Then that's all you had to say.  \n",
       "695                                                             -  \n",
       "694                  You never wanted to go out with 'me did you?  \n",
       "693                                                        I was?  \n",
       "663                                                             -  \n",
       "662                                                          Tons  \n",
       "578                                                             -  \n",
       "577                          I believe we share an art instructor  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing for deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping the just the pair of messages\n",
    "df = messages[messages['msg_2'] != '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg_line</th>\n",
       "      <th>user1_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>msg</th>\n",
       "      <th>msg_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>msg_line_clean</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>L1044</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>They do to!</td>\n",
       "      <td>They do not!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>L984</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>She okay?</td>\n",
       "      <td>I hope so.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>L924</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>Wow</td>\n",
       "      <td>Let's go.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>L871</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>No</td>\n",
       "      <td>Okay -- you're gonna need to learn how to lie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>\"L870</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I'm kidding.  You know how sometimes you just ...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>\"L868</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>The \"\"real you\"\".\"</td>\n",
       "      <td>Like my fear of wearing pastels?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>L867</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>What good stuff?</td>\n",
       "      <td>The \"\"real you\"\".\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>L866</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>I figured you'd get to the good stuff eventually.</td>\n",
       "      <td>What good stuff?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>L864</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Me.  This endless ...blonde babble. I'm like b...</td>\n",
       "      <td>Thank God!  If I had to hear one more story ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>L863</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>What crap?</td>\n",
       "      <td>Me.  This endless ...blonde babble. I'm like b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               msg_line user1_id movie_id user_name  \\\n",
       "msg_line_clean                                        \n",
       "1044              L1044       u2       m0   CAMERON   \n",
       "984                L984       u2       m0   CAMERON   \n",
       "924                L924       u2       m0   CAMERON   \n",
       "871                L871       u2       m0   CAMERON   \n",
       "870               \"L870       u0       m0    BIANCA   \n",
       "868               \"L868       u2       m0   CAMERON   \n",
       "867                L867       u0       m0    BIANCA   \n",
       "866                L866       u2       m0   CAMERON   \n",
       "864                L864       u0       m0    BIANCA   \n",
       "863                L863       u2       m0   CAMERON   \n",
       "\n",
       "                                                              msg  \\\n",
       "msg_line_clean                                                      \n",
       "1044                                                  They do to!   \n",
       "984                                                     She okay?   \n",
       "924                                                           Wow   \n",
       "871                                                            No   \n",
       "870             I'm kidding.  You know how sometimes you just ...   \n",
       "868                                            The \"\"real you\"\".\"   \n",
       "867                                              What good stuff?   \n",
       "866             I figured you'd get to the good stuff eventually.   \n",
       "864             Me.  This endless ...blonde babble. I'm like b...   \n",
       "863                                                    What crap?   \n",
       "\n",
       "                                                            msg_2  \n",
       "msg_line_clean                                                     \n",
       "1044                                                 They do not!  \n",
       "984                                                    I hope so.  \n",
       "924                                                     Let's go.  \n",
       "871                Okay -- you're gonna need to learn how to lie.  \n",
       "870                                                            No  \n",
       "868                              Like my fear of wearing pastels?  \n",
       "867                                            The \"\"real you\"\".\"  \n",
       "866                                              What good stuff?  \n",
       "864             Thank God!  If I had to hear one more story ab...  \n",
       "863             Me.  This endless ...blonde babble. I'm like b...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processamento_texto(corpus):\n",
    "    #tokenizacao\n",
    "    corpus_alt = re.findall(r\"\\w+(?:'\\w+)?|[^\\w\\s]\", corpus)\n",
    "    #capitalizacao\n",
    "    corpus_alt = [t.lower() for t in corpus_alt]\n",
    "    #lammatization\n",
    "    #sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
    "    \n",
    "    #stemming\n",
    "    #TODO\n",
    "    \n",
    "    #remover stopwords\n",
    "    #stopwords_ = stopwords.words(\"portuguese\")\n",
    "    #corpus_alt = [t for t in corpus_alt if t not in stopwords_]\n",
    "    #remover numero\n",
    "    #corpus_alt = [re.sub(r\"\\d\",\"\",t) for t in corpus_alt]\n",
    "    #remover pontuacoes\n",
    "    #corpus_alt = [t for t in corpus_alt if t not in string.punctuation]\n",
    "\n",
    "    return corpus_alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-761e6edbaf18>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['msg_proc'] = [pre_processamento_texto(str(txt)) for txt in df['msg']]\n"
     ]
    }
   ],
   "source": [
    "df['msg_proc'] = [pre_processamento_texto(str(txt)) for txt in df['msg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-ec576d7df925>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['msg_2_proc'] = [pre_processamento_texto(str(txt)) for txt in df['msg_2']]\n"
     ]
    }
   ],
   "source": [
    "df['msg_2_proc'] = [pre_processamento_texto(str(txt)) for txt in df['msg_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg_line</th>\n",
       "      <th>user1_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>msg</th>\n",
       "      <th>msg_2</th>\n",
       "      <th>msg_proc</th>\n",
       "      <th>msg_2_proc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>msg_line_clean</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>L1044</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>They do to!</td>\n",
       "      <td>They do not!</td>\n",
       "      <td>[they, do, to, !]</td>\n",
       "      <td>[they, do, not, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>L984</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>She okay?</td>\n",
       "      <td>I hope so.</td>\n",
       "      <td>[she, okay, ?]</td>\n",
       "      <td>[i, hope, so, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>L924</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>Wow</td>\n",
       "      <td>Let's go.</td>\n",
       "      <td>[wow]</td>\n",
       "      <td>[let's, go, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>L871</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>No</td>\n",
       "      <td>Okay -- you're gonna need to learn how to lie.</td>\n",
       "      <td>[no]</td>\n",
       "      <td>[okay, -, -, you're, gonna, need, to, learn, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>\"L870</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I'm kidding.  You know how sometimes you just ...</td>\n",
       "      <td>No</td>\n",
       "      <td>[i'm, kidding, ., you, know, how, sometimes, y...</td>\n",
       "      <td>[no]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666520</th>\n",
       "      <td>L666520</td>\n",
       "      <td>u9034</td>\n",
       "      <td>m616</td>\n",
       "      <td>VEREKER</td>\n",
       "      <td>Well I assure you Sir I have no desire to crea...</td>\n",
       "      <td>And I assure you you do not In fact I'd be obl...</td>\n",
       "      <td>[well, i, assure, you, sir, i, have, no, desir...</td>\n",
       "      <td>[and, i, assure, you, you, do, not, in, fact, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666371</th>\n",
       "      <td>L666371</td>\n",
       "      <td>u9030</td>\n",
       "      <td>m616</td>\n",
       "      <td>DURNFORD</td>\n",
       "      <td>Lord Chelmsford seems to want me to stay back ...</td>\n",
       "      <td>I think Chelmsford wants a good man on the bor...</td>\n",
       "      <td>[lord, chelmsford, seems, to, want, me, to, st...</td>\n",
       "      <td>[i, think, chelmsford, wants, a, good, man, on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666370</th>\n",
       "      <td>L666370</td>\n",
       "      <td>u9034</td>\n",
       "      <td>m616</td>\n",
       "      <td>VEREKER</td>\n",
       "      <td>I'm to take the Sikali with the main column to...</td>\n",
       "      <td>Lord Chelmsford seems to want me to stay back ...</td>\n",
       "      <td>[i'm, to, take, the, sikali, with, the, main, ...</td>\n",
       "      <td>[lord, chelmsford, seems, to, want, me, to, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666369</th>\n",
       "      <td>L666369</td>\n",
       "      <td>u9030</td>\n",
       "      <td>m616</td>\n",
       "      <td>DURNFORD</td>\n",
       "      <td>Your orders Mr Vereker?</td>\n",
       "      <td>I'm to take the Sikali with the main column to...</td>\n",
       "      <td>[your, orders, mr, vereker, ?]</td>\n",
       "      <td>[i'm, to, take, the, sikali, with, the, main, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666256</th>\n",
       "      <td>L666256</td>\n",
       "      <td>u9034</td>\n",
       "      <td>m616</td>\n",
       "      <td>VEREKER</td>\n",
       "      <td>Colonel Durnford... William Vereker. I hear yo...</td>\n",
       "      <td>Good ones yes Mr Vereker. Gentlemen who can ri...</td>\n",
       "      <td>[colonel, durnford, ., ., ., william, vereker,...</td>\n",
       "      <td>[good, ones, yes, mr, vereker, ., gentlemen, w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221616 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               msg_line user1_id movie_id user_name  \\\n",
       "msg_line_clean                                        \n",
       "1044              L1044       u2       m0   CAMERON   \n",
       "984                L984       u2       m0   CAMERON   \n",
       "924                L924       u2       m0   CAMERON   \n",
       "871                L871       u2       m0   CAMERON   \n",
       "870               \"L870       u0       m0    BIANCA   \n",
       "...                 ...      ...      ...       ...   \n",
       "666520          L666520    u9034     m616   VEREKER   \n",
       "666371          L666371    u9030     m616  DURNFORD   \n",
       "666370          L666370    u9034     m616   VEREKER   \n",
       "666369          L666369    u9030     m616  DURNFORD   \n",
       "666256          L666256    u9034     m616   VEREKER   \n",
       "\n",
       "                                                              msg  \\\n",
       "msg_line_clean                                                      \n",
       "1044                                                  They do to!   \n",
       "984                                                     She okay?   \n",
       "924                                                           Wow   \n",
       "871                                                            No   \n",
       "870             I'm kidding.  You know how sometimes you just ...   \n",
       "...                                                           ...   \n",
       "666520          Well I assure you Sir I have no desire to crea...   \n",
       "666371          Lord Chelmsford seems to want me to stay back ...   \n",
       "666370          I'm to take the Sikali with the main column to...   \n",
       "666369                                    Your orders Mr Vereker?   \n",
       "666256          Colonel Durnford... William Vereker. I hear yo...   \n",
       "\n",
       "                                                            msg_2  \\\n",
       "msg_line_clean                                                      \n",
       "1044                                                 They do not!   \n",
       "984                                                    I hope so.   \n",
       "924                                                     Let's go.   \n",
       "871                Okay -- you're gonna need to learn how to lie.   \n",
       "870                                                            No   \n",
       "...                                                           ...   \n",
       "666520          And I assure you you do not In fact I'd be obl...   \n",
       "666371          I think Chelmsford wants a good man on the bor...   \n",
       "666370          Lord Chelmsford seems to want me to stay back ...   \n",
       "666369          I'm to take the Sikali with the main column to...   \n",
       "666256          Good ones yes Mr Vereker. Gentlemen who can ri...   \n",
       "\n",
       "                                                         msg_proc  \\\n",
       "msg_line_clean                                                      \n",
       "1044                                            [they, do, to, !]   \n",
       "984                                                [she, okay, ?]   \n",
       "924                                                         [wow]   \n",
       "871                                                          [no]   \n",
       "870             [i'm, kidding, ., you, know, how, sometimes, y...   \n",
       "...                                                           ...   \n",
       "666520          [well, i, assure, you, sir, i, have, no, desir...   \n",
       "666371          [lord, chelmsford, seems, to, want, me, to, st...   \n",
       "666370          [i'm, to, take, the, sikali, with, the, main, ...   \n",
       "666369                             [your, orders, mr, vereker, ?]   \n",
       "666256          [colonel, durnford, ., ., ., william, vereker,...   \n",
       "\n",
       "                                                       msg_2_proc  \n",
       "msg_line_clean                                                     \n",
       "1044                                           [they, do, not, !]  \n",
       "984                                              [i, hope, so, .]  \n",
       "924                                                [let's, go, .]  \n",
       "871             [okay, -, -, you're, gonna, need, to, learn, h...  \n",
       "870                                                          [no]  \n",
       "...                                                           ...  \n",
       "666520          [and, i, assure, you, you, do, not, in, fact, ...  \n",
       "666371          [i, think, chelmsford, wants, a, good, man, on...  \n",
       "666370          [lord, chelmsford, seems, to, want, me, to, st...  \n",
       "666369          [i'm, to, take, the, sikali, with, the, main, ...  \n",
       "666256          [good, ones, yes, mr, vereker, ., gentlemen, w...  \n",
       "\n",
       "[221616 rows x 8 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-bb7fe2566607>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['msg'] = df['msg'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "df['msg'] = df['msg'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-f263fbba459d>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['msg_2'] = df['msg_2'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "df['msg_2'] = df['msg_2'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# primeiro criamos o objeto\n",
    "vect_bag = CountVectorizer(binary=True) #se binary = False -> ocorre a contagem da frequência em que a palavra aparece\n",
    "vect_bow = vect_bag.fit_transform(df['msg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '007',\n",
       " '0088',\n",
       " '009843',\n",
       " '010',\n",
       " '0100',\n",
       " '0130',\n",
       " '015',\n",
       " '01766',\n",
       " '0199',\n",
       " '02pm',\n",
       " '03',\n",
       " '0300',\n",
       " '04',\n",
       " '05',\n",
       " '0500',\n",
       " '06',\n",
       " '0630',\n",
       " '07410',\n",
       " '0800',\n",
       " '0821',\n",
       " '09',\n",
       " '0900',\n",
       " '0972',\n",
       " '0h',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '10000',\n",
       " '100000',\n",
       " '1002',\n",
       " '1009',\n",
       " '101',\n",
       " '1012',\n",
       " '101st',\n",
       " '104',\n",
       " '105',\n",
       " '106',\n",
       " '1060',\n",
       " '108',\n",
       " '109',\n",
       " '1098',\n",
       " '10cc',\n",
       " '10th',\n",
       " '11',\n",
       " '110',\n",
       " '1138',\n",
       " '114',\n",
       " '115',\n",
       " '119',\n",
       " '11speak',\n",
       " '11th',\n",
       " '12',\n",
       " '120',\n",
       " '1200',\n",
       " '12000',\n",
       " '120000',\n",
       " '1208',\n",
       " '122',\n",
       " '124',\n",
       " '125',\n",
       " '125th',\n",
       " '127',\n",
       " '1274',\n",
       " '1294',\n",
       " '12th',\n",
       " '13',\n",
       " '130',\n",
       " '131',\n",
       " '132',\n",
       " '1320',\n",
       " '1322',\n",
       " '133',\n",
       " '134',\n",
       " '135',\n",
       " '137',\n",
       " '138',\n",
       " '139',\n",
       " '13th',\n",
       " '14',\n",
       " '140',\n",
       " '14000',\n",
       " '1412',\n",
       " '1425',\n",
       " '143',\n",
       " '1436',\n",
       " '1443',\n",
       " '145',\n",
       " '146',\n",
       " '147',\n",
       " '1490',\n",
       " '14b',\n",
       " '14th',\n",
       " '15',\n",
       " '150',\n",
       " '1500',\n",
       " '15000',\n",
       " '1505',\n",
       " '153',\n",
       " '1530',\n",
       " '154',\n",
       " '155',\n",
       " '1550',\n",
       " '156',\n",
       " '15th',\n",
       " '16',\n",
       " '160',\n",
       " '1600',\n",
       " '161',\n",
       " '1610',\n",
       " '1620',\n",
       " '167',\n",
       " '1672',\n",
       " '16m',\n",
       " '16mm',\n",
       " '16s',\n",
       " '16th',\n",
       " '17',\n",
       " '1700',\n",
       " '1712',\n",
       " '1713',\n",
       " '1718',\n",
       " '175',\n",
       " '1769',\n",
       " '178',\n",
       " '1787',\n",
       " '1789',\n",
       " '1791',\n",
       " '1792',\n",
       " '17c',\n",
       " '17th',\n",
       " '18',\n",
       " '180',\n",
       " '1800',\n",
       " '18000',\n",
       " '180000',\n",
       " '1804',\n",
       " '180th',\n",
       " '1814',\n",
       " '18250',\n",
       " '183',\n",
       " '1835',\n",
       " '184',\n",
       " '1840',\n",
       " '1852',\n",
       " '1854',\n",
       " '1856',\n",
       " '1857',\n",
       " '1858',\n",
       " '1862',\n",
       " '1865',\n",
       " '1867',\n",
       " '1868',\n",
       " '1870',\n",
       " '1871',\n",
       " '1872',\n",
       " '1879',\n",
       " '188',\n",
       " '1886',\n",
       " '1888',\n",
       " '1890',\n",
       " '1893',\n",
       " '1894',\n",
       " '1895',\n",
       " '1896',\n",
       " '1898',\n",
       " '1899',\n",
       " '18k',\n",
       " '18th',\n",
       " '19',\n",
       " '190',\n",
       " '1900',\n",
       " '1904',\n",
       " '1905',\n",
       " '1912',\n",
       " '1914',\n",
       " '1915',\n",
       " '1916',\n",
       " '1917',\n",
       " '1919',\n",
       " '1920',\n",
       " '1920s',\n",
       " '1921',\n",
       " '1922',\n",
       " '1923',\n",
       " '1927',\n",
       " '1930',\n",
       " '1932',\n",
       " '1934',\n",
       " '1935',\n",
       " '1936',\n",
       " '1937',\n",
       " '1938',\n",
       " '1939',\n",
       " '1940',\n",
       " '1941',\n",
       " '1942',\n",
       " '1945',\n",
       " '1946',\n",
       " '1947',\n",
       " '1948',\n",
       " '1949',\n",
       " '195',\n",
       " '1950',\n",
       " '1952',\n",
       " '1953',\n",
       " '1956',\n",
       " '1957',\n",
       " '1958',\n",
       " '1959',\n",
       " '1960',\n",
       " '1961',\n",
       " '1962',\n",
       " '1963',\n",
       " '1964',\n",
       " '1965',\n",
       " '1966',\n",
       " '1967',\n",
       " '1968',\n",
       " '1969',\n",
       " '1970',\n",
       " '1971',\n",
       " '1972',\n",
       " '1973',\n",
       " '1974',\n",
       " '1975',\n",
       " '1976',\n",
       " '1977',\n",
       " '1978',\n",
       " '1979',\n",
       " '198',\n",
       " '1980',\n",
       " '1981',\n",
       " '1982',\n",
       " '1983',\n",
       " '1984',\n",
       " '1985',\n",
       " '1986',\n",
       " '1988',\n",
       " '1989',\n",
       " '1990',\n",
       " '1992',\n",
       " '1993',\n",
       " '1995',\n",
       " '1996',\n",
       " '1997',\n",
       " '1998',\n",
       " '19th',\n",
       " '1egal',\n",
       " '1l',\n",
       " '1ove',\n",
       " '1st',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '20000',\n",
       " '200000',\n",
       " '20000000',\n",
       " '2001',\n",
       " '2004',\n",
       " '2005',\n",
       " '2006',\n",
       " '201',\n",
       " '2015',\n",
       " '2016',\n",
       " '2017',\n",
       " '202',\n",
       " '2034',\n",
       " '2036',\n",
       " '2041',\n",
       " '205',\n",
       " '209',\n",
       " '20s',\n",
       " '20th',\n",
       " '21',\n",
       " '210',\n",
       " '2100',\n",
       " '211',\n",
       " '212',\n",
       " '213',\n",
       " '215',\n",
       " '216',\n",
       " '2187',\n",
       " '21st',\n",
       " '22',\n",
       " '220',\n",
       " '2222',\n",
       " '2224',\n",
       " '22350',\n",
       " '2245',\n",
       " '225',\n",
       " '226',\n",
       " '22nd',\n",
       " '23',\n",
       " '230',\n",
       " '2300',\n",
       " '231',\n",
       " '235',\n",
       " '237',\n",
       " '23763273',\n",
       " '23rd',\n",
       " '24',\n",
       " '240',\n",
       " '2400',\n",
       " '241',\n",
       " '2415',\n",
       " '247',\n",
       " '24k',\n",
       " '24th',\n",
       " '25',\n",
       " '250',\n",
       " '2500',\n",
       " '25000',\n",
       " '250000',\n",
       " '253',\n",
       " '254',\n",
       " '255',\n",
       " '256',\n",
       " '257',\n",
       " '259',\n",
       " '25s',\n",
       " '25th',\n",
       " '26',\n",
       " '2600',\n",
       " '262',\n",
       " '2627',\n",
       " '266',\n",
       " '2684',\n",
       " '26th',\n",
       " '27',\n",
       " '270',\n",
       " '2702',\n",
       " '2735',\n",
       " '275',\n",
       " '27b',\n",
       " '28',\n",
       " '280',\n",
       " '283',\n",
       " '2841',\n",
       " '285',\n",
       " '289',\n",
       " '28th',\n",
       " '29',\n",
       " '290',\n",
       " '29th',\n",
       " '2nd',\n",
       " '2t',\n",
       " '2x',\n",
       " '2x4',\n",
       " '2xy',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '30000',\n",
       " '300000',\n",
       " '3000w',\n",
       " '300th',\n",
       " '302',\n",
       " '303',\n",
       " '304',\n",
       " '305',\n",
       " '306',\n",
       " '308',\n",
       " '30pm',\n",
       " '30th',\n",
       " '31',\n",
       " '310',\n",
       " '3100',\n",
       " '31259',\n",
       " '314',\n",
       " '315',\n",
       " '316',\n",
       " '318',\n",
       " '31st',\n",
       " '32',\n",
       " '32000',\n",
       " '325',\n",
       " '325th',\n",
       " '327',\n",
       " '328',\n",
       " '33',\n",
       " '330',\n",
       " '337',\n",
       " '33rd',\n",
       " '34',\n",
       " '3407',\n",
       " '3417',\n",
       " '342834',\n",
       " '3444',\n",
       " '347',\n",
       " '3489',\n",
       " '34th',\n",
       " '35',\n",
       " '350',\n",
       " '3500',\n",
       " '35000',\n",
       " '350000',\n",
       " '3511',\n",
       " '353',\n",
       " '357',\n",
       " '36',\n",
       " '364000',\n",
       " '365',\n",
       " '3680',\n",
       " '36d',\n",
       " '37',\n",
       " '37000',\n",
       " '38',\n",
       " '383',\n",
       " '3860',\n",
       " '38s',\n",
       " '39',\n",
       " '3900',\n",
       " '395',\n",
       " '3b',\n",
       " '3cpo',\n",
       " '3d',\n",
       " '3del',\n",
       " '3jane',\n",
       " '3k',\n",
       " '3rd',\n",
       " '3ya',\n",
       " '40',\n",
       " '400',\n",
       " '4000',\n",
       " '40000',\n",
       " '401',\n",
       " '403',\n",
       " '404',\n",
       " '405',\n",
       " '405th',\n",
       " '406',\n",
       " '409',\n",
       " '40th',\n",
       " '41',\n",
       " '410',\n",
       " '412',\n",
       " '414',\n",
       " '415',\n",
       " '41st',\n",
       " '42',\n",
       " '4200',\n",
       " '4202',\n",
       " '4215',\n",
       " '422',\n",
       " '426',\n",
       " '42nd',\n",
       " '43',\n",
       " '43rd',\n",
       " '44',\n",
       " '440',\n",
       " '4410',\n",
       " '4421',\n",
       " '44th',\n",
       " '45',\n",
       " '450',\n",
       " '4500',\n",
       " '453',\n",
       " '454',\n",
       " '459',\n",
       " '45th',\n",
       " '46',\n",
       " '467',\n",
       " '4685',\n",
       " '47',\n",
       " '471',\n",
       " '472',\n",
       " '4732',\n",
       " '478',\n",
       " '47th',\n",
       " '48',\n",
       " '4800',\n",
       " '4817',\n",
       " '483',\n",
       " '484',\n",
       " '49',\n",
       " '49th',\n",
       " '4g',\n",
       " '4o',\n",
       " '4th',\n",
       " '50',\n",
       " '500',\n",
       " '5000',\n",
       " '50000',\n",
       " '500000',\n",
       " '501',\n",
       " '504',\n",
       " '509',\n",
       " '50s',\n",
       " '50th',\n",
       " '51',\n",
       " '512',\n",
       " '5151',\n",
       " '52',\n",
       " '53',\n",
       " '531',\n",
       " '54',\n",
       " '545',\n",
       " '54th',\n",
       " '55',\n",
       " '550',\n",
       " '555',\n",
       " '5555',\n",
       " '5598',\n",
       " '56',\n",
       " '5601',\n",
       " '561',\n",
       " '57',\n",
       " '579b',\n",
       " '57th',\n",
       " '58',\n",
       " '5827b',\n",
       " '58th',\n",
       " '59',\n",
       " '590',\n",
       " '5946',\n",
       " '59th',\n",
       " '5th',\n",
       " '60',\n",
       " '600',\n",
       " '6000',\n",
       " '60000',\n",
       " '600000',\n",
       " '605',\n",
       " '60s',\n",
       " '61',\n",
       " '610',\n",
       " '61s',\n",
       " '62',\n",
       " '622',\n",
       " '62nd',\n",
       " '63',\n",
       " '639',\n",
       " '63rd',\n",
       " '64',\n",
       " '642',\n",
       " '6421',\n",
       " '645',\n",
       " '65',\n",
       " '65000',\n",
       " '655321',\n",
       " '656',\n",
       " '657',\n",
       " '66',\n",
       " '660',\n",
       " '666',\n",
       " '67',\n",
       " '67b',\n",
       " '67th',\n",
       " '68',\n",
       " '69',\n",
       " '6th',\n",
       " '70',\n",
       " '700',\n",
       " '7000',\n",
       " '7000000',\n",
       " '701',\n",
       " '702',\n",
       " '703',\n",
       " '7099',\n",
       " '71',\n",
       " '72',\n",
       " '727',\n",
       " '73',\n",
       " '732',\n",
       " '7393',\n",
       " '73rd',\n",
       " '74',\n",
       " '747',\n",
       " '75',\n",
       " '750',\n",
       " '75000',\n",
       " '750000',\n",
       " '753',\n",
       " '7548',\n",
       " '76',\n",
       " '76th',\n",
       " '77',\n",
       " '770',\n",
       " '77th',\n",
       " '78',\n",
       " '7881',\n",
       " '78s',\n",
       " '78th',\n",
       " '79',\n",
       " '79th',\n",
       " '7a',\n",
       " '7mm',\n",
       " '7th',\n",
       " '80',\n",
       " '800',\n",
       " '8000',\n",
       " '800000',\n",
       " '801',\n",
       " '803',\n",
       " '8095',\n",
       " '80s',\n",
       " '81',\n",
       " '8150',\n",
       " '818',\n",
       " '81st',\n",
       " '82',\n",
       " '82m',\n",
       " '83',\n",
       " '84',\n",
       " '842',\n",
       " '843d',\n",
       " '843rd',\n",
       " '85',\n",
       " '850',\n",
       " '8500',\n",
       " '85000',\n",
       " '8563',\n",
       " '86',\n",
       " '861',\n",
       " '87',\n",
       " '8700',\n",
       " '88',\n",
       " '89',\n",
       " '89970',\n",
       " '8a',\n",
       " '8th',\n",
       " '8ths',\n",
       " '90',\n",
       " '900',\n",
       " '9000',\n",
       " '90210',\n",
       " '90222',\n",
       " '9027',\n",
       " '908',\n",
       " '91',\n",
       " '911',\n",
       " '91403',\n",
       " '92',\n",
       " '93',\n",
       " '94',\n",
       " '94107',\n",
       " '944',\n",
       " '95',\n",
       " '96',\n",
       " '97',\n",
       " '976',\n",
       " '98',\n",
       " '9876',\n",
       " '99',\n",
       " '9962',\n",
       " '9d',\n",
       " '9th',\n",
       " '_22nd_',\n",
       " '_and_',\n",
       " '_answer_',\n",
       " '_are_',\n",
       " '_asleep_',\n",
       " '_bonehead_',\n",
       " '_died_',\n",
       " '_had_',\n",
       " '_insomnolesence_',\n",
       " '_jason',\n",
       " '_knowledge_',\n",
       " '_krueger_',\n",
       " '_me_',\n",
       " '_months_',\n",
       " '_movie_',\n",
       " '_neurolar_',\n",
       " '_nothing_',\n",
       " '_other_',\n",
       " '_owe_',\n",
       " '_rolls_',\n",
       " '_second_',\n",
       " '_took_',\n",
       " '_two_',\n",
       " '_was_',\n",
       " '_we',\n",
       " '_we_',\n",
       " '_you_',\n",
       " '_your_',\n",
       " 'a2',\n",
       " 'a4',\n",
       " 'aa',\n",
       " 'aaa',\n",
       " 'aaaaa',\n",
       " 'aaaaaa',\n",
       " 'aaaaaaaaaaaa',\n",
       " 'aaaaaaaaaaaaaa',\n",
       " 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa',\n",
       " 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa',\n",
       " 'aaaaaaah',\n",
       " 'aaaaaahhhhooowwwoooooooooooooooooooooo',\n",
       " 'aaaaahhnnnhaaaaaannnhhh',\n",
       " 'aaaaannnnnuuunnnuhhhhh',\n",
       " 'aaaaawww',\n",
       " 'aaaaeeehhhhg',\n",
       " 'aaaagh',\n",
       " 'aaaah',\n",
       " 'aaaahh',\n",
       " 'aaaahhh',\n",
       " 'aaaahhhh',\n",
       " 'aaaand',\n",
       " 'aaaarghh',\n",
       " 'aaaayouiaaaeeeeeeee',\n",
       " 'aaabout',\n",
       " 'aaach',\n",
       " 'aaagh',\n",
       " 'aaah',\n",
       " 'aaahghhh',\n",
       " 'aaahhh',\n",
       " 'aaahhnnnahnnnn',\n",
       " 'aaand',\n",
       " 'aaaww',\n",
       " 'aaayeeee',\n",
       " 'aach',\n",
       " 'aagh',\n",
       " 'aaghgh',\n",
       " 'aah',\n",
       " 'aahby',\n",
       " 'aahhh',\n",
       " 'aahhhhnnnaaahahnn',\n",
       " 'aannnnaahhnn',\n",
       " 'aap',\n",
       " 'aardvark',\n",
       " 'aaron',\n",
       " 'aaronow',\n",
       " 'ab',\n",
       " 'aback',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abandonment',\n",
       " 'abated',\n",
       " 'abattoir',\n",
       " 'abba',\n",
       " 'abbe',\n",
       " 'abbey',\n",
       " 'abbittmm',\n",
       " 'abbott',\n",
       " 'abby',\n",
       " 'abc',\n",
       " 'abdicate',\n",
       " 'abdicated',\n",
       " 'abdomen',\n",
       " 'abdominal',\n",
       " 'abduct',\n",
       " 'abducted',\n",
       " 'abduction',\n",
       " 'abductor',\n",
       " 'abducts',\n",
       " 'abdul',\n",
       " 'abdullah',\n",
       " 'abe',\n",
       " 'abel',\n",
       " 'aber',\n",
       " 'aberdeen',\n",
       " 'aberration',\n",
       " 'abetting',\n",
       " 'abhor',\n",
       " 'abhorrent',\n",
       " 'abi1ities',\n",
       " 'abide',\n",
       " 'abiding',\n",
       " 'abigail',\n",
       " 'abilene',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'abitazione',\n",
       " 'ablative',\n",
       " 'able',\n",
       " 'ablest',\n",
       " 'ablutions',\n",
       " 'abnormal',\n",
       " 'abnormally',\n",
       " 'aboard',\n",
       " 'abode',\n",
       " 'abolished',\n",
       " 'abolishment',\n",
       " 'abolofia',\n",
       " 'abominable',\n",
       " 'abomination',\n",
       " 'aboot',\n",
       " 'abort',\n",
       " 'aborted',\n",
       " 'aborticide',\n",
       " 'abortion',\n",
       " 'abortionist',\n",
       " 'abortions',\n",
       " 'abou',\n",
       " 'aboukir',\n",
       " 'about',\n",
       " 'aboutâ',\n",
       " 'above',\n",
       " 'abracadabra',\n",
       " 'abraham',\n",
       " 'abrams',\n",
       " 'abrasions',\n",
       " 'abreast',\n",
       " 'abroad',\n",
       " 'abrupt',\n",
       " 'abruptly',\n",
       " 'abruzzi',\n",
       " 'abs',\n",
       " 'absance',\n",
       " 'absconded',\n",
       " 'absence',\n",
       " 'absent',\n",
       " 'absenteeism',\n",
       " 'absentia',\n",
       " 'absenting',\n",
       " 'absently',\n",
       " 'absinthe',\n",
       " 'abslovo',\n",
       " 'abso',\n",
       " 'absol',\n",
       " 'absolu',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absolutes',\n",
       " 'absolution',\n",
       " 'absolve',\n",
       " 'absolved',\n",
       " 'absorb',\n",
       " 'absorbed',\n",
       " 'absorbing',\n",
       " 'absorbs',\n",
       " 'absorption',\n",
       " 'abstain',\n",
       " 'abstaining',\n",
       " 'abstinence',\n",
       " 'abstract',\n",
       " 'abstraction',\n",
       " 'absurd',\n",
       " 'absurde',\n",
       " 'absurdity',\n",
       " 'abu',\n",
       " 'abuildin',\n",
       " 'abun',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'abundantly',\n",
       " 'abundas',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abuser',\n",
       " 'abuses',\n",
       " 'abusing',\n",
       " 'abusive',\n",
       " 'abut',\n",
       " 'abyss',\n",
       " 'abyssinian',\n",
       " 'abyssinians',\n",
       " 'ac',\n",
       " 'acacia',\n",
       " 'acacias',\n",
       " 'academic',\n",
       " 'academics',\n",
       " 'academy',\n",
       " 'acapulco',\n",
       " 'acca',\n",
       " 'accelerant',\n",
       " 'accelerate',\n",
       " 'accelerated',\n",
       " 'accelerating',\n",
       " 'acceleration',\n",
       " 'accelerator',\n",
       " 'accelerators',\n",
       " 'accent',\n",
       " 'accents',\n",
       " 'accentuate',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptance',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'accepts',\n",
       " 'accesory',\n",
       " 'access',\n",
       " 'accessed',\n",
       " 'accesses',\n",
       " 'accessible',\n",
       " 'accessing',\n",
       " 'accessories',\n",
       " 'accessorizing',\n",
       " 'accessory',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'accidente',\n",
       " 'accidently',\n",
       " 'accidents',\n",
       " 'acclaimed',\n",
       " 'acclimate',\n",
       " 'accommodate',\n",
       " 'accommodated',\n",
       " 'accommodating',\n",
       " 'accommodation',\n",
       " 'accommodations',\n",
       " 'accomodatedd',\n",
       " 'accomodations',\n",
       " 'accompanied',\n",
       " 'accompanies',\n",
       " 'accompany',\n",
       " 'accompanying',\n",
       " 'accompli',\n",
       " 'accomplice',\n",
       " 'accomplices',\n",
       " 'accomplised',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishes',\n",
       " 'accomplishing',\n",
       " 'accomplishment',\n",
       " 'accomplishments',\n",
       " 'accompluh',\n",
       " 'accord',\n",
       " 'accordance',\n",
       " 'accorded',\n",
       " 'accordin',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'accords',\n",
       " 'accosted',\n",
       " 'account',\n",
       " 'accounta',\n",
       " 'accountability',\n",
       " 'accountable',\n",
       " 'accountant',\n",
       " 'accountants',\n",
       " 'accounted',\n",
       " 'accounting',\n",
       " 'accounts',\n",
       " 'accountâ',\n",
       " 'accredited',\n",
       " 'accump',\n",
       " 'accumulate',\n",
       " 'accumulated',\n",
       " 'accumulation',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accusation',\n",
       " 'accusations',\n",
       " 'accuse',\n",
       " 'accused',\n",
       " 'accusing',\n",
       " 'accustomed',\n",
       " 'ace',\n",
       " 'aced',\n",
       " 'acer',\n",
       " 'aces',\n",
       " 'acetate',\n",
       " 'acetylene',\n",
       " 'ach',\n",
       " 'achat',\n",
       " 'ache',\n",
       " 'acheron',\n",
       " 'aches',\n",
       " 'acheson',\n",
       " 'achetăš',\n",
       " 'achhh',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achievement',\n",
       " 'achievements',\n",
       " 'achiever',\n",
       " 'achievers',\n",
       " 'achieving',\n",
       " 'achilles',\n",
       " 'achin',\n",
       " 'aching',\n",
       " 'achingly',\n",
       " 'acid',\n",
       " 'acids',\n",
       " 'ackerman',\n",
       " 'ackland',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'acknowledgement',\n",
       " 'acknowledgements',\n",
       " 'acknowledging',\n",
       " 'acl',\n",
       " 'acme',\n",
       " 'acne',\n",
       " 'acned',\n",
       " 'aconite',\n",
       " 'acorn',\n",
       " 'acorns',\n",
       " 'acosta',\n",
       " 'acount',\n",
       " 'acoustic',\n",
       " 'acquaintance',\n",
       " 'acquaintances',\n",
       " 'acquainted',\n",
       " 'acquiesce',\n",
       " 'acquiesced',\n",
       " 'acquintance',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'acquires',\n",
       " 'acquiring',\n",
       " 'acquisition',\n",
       " 'acquisitions',\n",
       " 'acquit',\n",
       " 'acquittal',\n",
       " ...]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_bag.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 38274)\t1\n",
      "  (0, 11321)\t1\n",
      "  (0, 38682)\t1\n",
      "  (1, 34042)\t1\n",
      "  (1, 26594)\t1\n",
      "  (2, 42470)\t1\n",
      "  (3, 25968)\t1\n",
      "  (4, 38682)\t1\n",
      "  (4, 20890)\t1\n",
      "  (4, 42769)\t1\n",
      "  (4, 21117)\t1\n",
      "  (4, 18398)\t1\n",
      "  (4, 35430)\t1\n",
      "  (4, 20614)\t1\n",
      "  (4, 3719)\t1\n",
      "  (4, 38328)\t1\n",
      "  (4, 28207)\t1\n",
      "  (4, 1918)\t1\n",
      "  (4, 11453)\t1\n",
      "  (4, 30413)\t1\n",
      "  (5, 42769)\t1\n",
      "  (5, 38190)\t1\n",
      "  (5, 30846)\t1\n",
      "  (6, 41799)\t1\n",
      "  (6, 16205)\t1\n",
      "  :\t:\n",
      "  (221612, 22531)\t1\n",
      "  (221612, 6870)\t1\n",
      "  (221612, 3535)\t1\n",
      "  (221613, 38682)\t1\n",
      "  (221613, 38190)\t1\n",
      "  (221613, 42247)\t1\n",
      "  (221613, 37631)\t1\n",
      "  (221613, 23012)\t1\n",
      "  (221613, 32189)\t1\n",
      "  (221613, 7843)\t1\n",
      "  (221613, 34549)\t1\n",
      "  (221614, 42781)\t1\n",
      "  (221614, 25074)\t1\n",
      "  (221614, 26855)\t1\n",
      "  (221614, 40787)\t1\n",
      "  (221615, 42769)\t1\n",
      "  (221615, 40683)\t1\n",
      "  (221615, 3767)\t1\n",
      "  (221615, 17492)\t1\n",
      "  (221615, 42089)\t1\n",
      "  (221615, 26531)\t1\n",
      "  (221615, 7806)\t1\n",
      "  (221615, 33602)\t1\n",
      "  (221615, 40787)\t1\n",
      "  (221615, 12014)\t1\n"
     ]
    }
   ],
   "source": [
    "print(vect_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>007</th>\n",
       "      <th>0088</th>\n",
       "      <th>009843</th>\n",
       "      <th>010</th>\n",
       "      <th>0100</th>\n",
       "      <th>0130</th>\n",
       "      <th>015</th>\n",
       "      <th>01766</th>\n",
       "      <th>...</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zus</th>\n",
       "      <th>zuul</th>\n",
       "      <th>zuzu</th>\n",
       "      <th>zwei</th>\n",
       "      <th>zwoelf</th>\n",
       "      <th>zydowski</th>\n",
       "      <th>zygmunt</th>\n",
       "      <th>zyprexa</th>\n",
       "      <th>zzzzzzzzzzzzzzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 43007 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  007  0088  009843  010  0100  0130  015  01766  ...  zurich  zus  \\\n",
       "0   0    0    0     0       0    0     0     0    0      0  ...       0    0   \n",
       "1   0    0    0     0       0    0     0     0    0      0  ...       0    0   \n",
       "2   0    0    0     0       0    0     0     0    0      0  ...       0    0   \n",
       "3   0    0    0     0       0    0     0     0    0      0  ...       0    0   \n",
       "4   0    0    0     0       0    0     0     0    0      0  ...       0    0   \n",
       "5   0    0    0     0       0    0     0     0    0      0  ...       0    0   \n",
       "6   0    0    0     0       0    0     0     0    0      0  ...       0    0   \n",
       "7   0    0    0     0       0    0     0     0    0      0  ...       0    0   \n",
       "8   0    0    0     0       0    0     0     0    0      0  ...       0    0   \n",
       "9   0    0    0     0       0    0     0     0    0      0  ...       0    0   \n",
       "\n",
       "   zuul  zuzu  zwei  zwoelf  zydowski  zygmunt  zyprexa  zzzzzzzzzzzzzzzz  \n",
       "0     0     0     0       0         0        0        0                 0  \n",
       "1     0     0     0       0         0        0        0                 0  \n",
       "2     0     0     0       0         0        0        0                 0  \n",
       "3     0     0     0       0         0        0        0                 0  \n",
       "4     0     0     0       0         0        0        0                 0  \n",
       "5     0     0     0       0         0        0        0                 0  \n",
       "6     0     0     0       0         0        0        0                 0  \n",
       "7     0     0     0       0         0        0        0                 0  \n",
       "8     0     0     0       0         0        0        0                 0  \n",
       "9     0     0     0       0         0        0        0                 0  \n",
       "\n",
       "[10 rows x 43007 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(vect_bow[0:10].todense(), columns=vect_bag.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small['msg'] = df['msg'][0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small['msg_2'] = df['msg_2'][0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = df_small['msg']\n",
    "train_y = df_small['msg_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "# define documents\n",
    "docs = train_x\n",
    "# create the tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "# fit the tokenizer on the documents\n",
    "tokenizer.fit_on_texts(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode training data set\n",
    "Xtrain = tokenizer.texts_to_matrix(train_x)\n",
    "# encode training data set\n",
    "Xtest = tokenizer.texts_to_matrix(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 7)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 7)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18350341907227397\n"
     ]
    }
   ],
   "source": [
    "print(distance.cosine(Xtrain[0], Xtest[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows, num_cols = Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/douglas/.local/lib/python3.8/site-packages/scipy/spatial/distance.py:714: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "list_similarity = []\n",
    "for i in range(num_rows):\n",
    "    d = distance.cosine(Xtrain[i], Xtest[i])\n",
    "    if math.isnan(d):\n",
    "        d = 0.05\n",
    "    list_similarity.append(d)\n",
    "    i+=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small['similarity'] = list_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg</th>\n",
       "      <th>msg_2</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>msg_line_clean</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>They do to!</td>\n",
       "      <td>They do not!</td>\n",
       "      <td>0.183503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>She okay?</td>\n",
       "      <td>I hope so.</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>Wow</td>\n",
       "      <td>Let's go.</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        msg         msg_2  similarity\n",
       "msg_line_clean                                       \n",
       "1044            They do to!  They do not!    0.183503\n",
       "984               She okay?    I hope so.    0.050000\n",
       "924                     Wow     Let's go.    0.050000"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_127 (Dense)            (None, 2)                 16        \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 25\n",
      "Trainable params: 25\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model - 3 layers. First layer 128 neurons, second layer 64 neurons and 3rd output layer contains number of neurons\n",
    "# equal to number of intents to predict output intent with softmax\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_dim=7, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
      "model created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "#fitting and saving the model\n",
    "hist = model.fit(Xtrain, df_small['similarity'], epochs=2, batch_size=3, verbose=1)\n",
    "model.save('chatbot_model.h5', hist)\n",
    "\n",
    "print(\"model created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = tokenizer.texts_to_matrix('what is the best movie?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 7) for input Tensor(\"dense_127_input:0\", shape=(None, 7), dtype=float32), but it was called on an input with incompatible shape (None, 23, 7).\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(np.array([p]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERROR_THRESHOLD = 0.25\n",
    "results = [[i,r] for i,r in enumerate(res) if r>ERROR_THRESHOLD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by strength of probability\n",
    "results.sort(key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, array([1.], dtype=float32)]\n",
      "[1, array([1.], dtype=float32)]\n",
      "[2, array([1.], dtype=float32)]\n",
      "[3, array([1.], dtype=float32)]\n",
      "[4, array([1.], dtype=float32)]\n",
      "[5, array([1.], dtype=float32)]\n",
      "[6, array([1.], dtype=float32)]\n",
      "[7, array([1.], dtype=float32)]\n",
      "[8, array([1.], dtype=float32)]\n",
      "[9, array([1.], dtype=float32)]\n",
      "[10, array([1.], dtype=float32)]\n",
      "[11, array([1.], dtype=float32)]\n",
      "[12, array([1.], dtype=float32)]\n",
      "[13, array([1.], dtype=float32)]\n",
      "[14, array([1.], dtype=float32)]\n",
      "[15, array([1.], dtype=float32)]\n",
      "[16, array([1.], dtype=float32)]\n",
      "[17, array([1.], dtype=float32)]\n",
      "[18, array([1.], dtype=float32)]\n",
      "[19, array([1.], dtype=float32)]\n",
      "[20, array([1.], dtype=float32)]\n",
      "[21, array([1.], dtype=float32)]\n",
      "[22, array([1.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "return_list = []\n",
    "i = 0\n",
    "for i in range(len(results)):\n",
    "    #return_list.append({\"intent\": df_small['msg_2'][i], \"probability\": str(i)})\n",
    "    print(results[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Template model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_115 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 19\n",
      "Trainable params: 19\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model - 3 layers. First layer 128 neurons, second layer 64 neurons and 3rd output layer contains number of neurons\n",
    "# equal to number of intents to predict output intent with softmax\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_dim=4, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3333\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3333\n",
      "model created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "#fitting and saving the model\n",
    "hist = model.fit(([1,2,3,4],[1,2,3,4],[1,2,3,4]), [1,2,3], epochs=2, batch_size=3, verbose=1)\n",
    "model.save('chatbot_model.h5', hist)\n",
    "\n",
    "print(\"model created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
