{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-BSEigEE-utQ"
   },
   "source": [
    "## A intenção do projeto é criar um chatbot baseado em reviews de filmes para que se possa fazer perguntas e manter uma conversa livre sobre este tema\n",
    "\n",
    "- link do banco de dados https://www.kaggle.com/Cornell-University/movie-dialog-corpus?select=movie_lines.tsv\n",
    "- referências\n",
    ">- https://shanebarker.com/blog/deep-learning-chatbot/\n",
    "> -https://towardsdatascience.com/how-to-create-a-chatbot-with-python-deep-learning-in-less-than-an-hour-56a063bdfc44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AgR-ezT5-utZ",
    "outputId": "f773f454-e438-42fd-81a2-70b325be7745"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/douglas/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import re\n",
    "import gensim\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from scipy.spatial import distance\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Um5L0h0-utn"
   },
   "source": [
    "### Opening movie reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Crtu4lkNCvuE"
   },
   "outputs": [],
   "source": [
    "messages = pd.read_csv('./chatdata/movie_lines_pre_processed.tsv', delimiter=\"\\t\", quoting=3, encoding='ISO-8859-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg_line</th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>msg</th>\n",
       "      <th>msg_2</th>\n",
       "      <th>msg_pre_processed</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L49</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>Did you change your hair?</td>\n",
       "      <td>No.</td>\n",
       "      <td>did you change your hair</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L50</td>\n",
       "      <td>u3</td>\n",
       "      <td>m0</td>\n",
       "      <td>No.</td>\n",
       "      <td>You might wanna think about it</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L51</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>You might wanna think about it</td>\n",
       "      <td>maybe...</td>\n",
       "      <td>you might wanna think about it</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L59</td>\n",
       "      <td>u9</td>\n",
       "      <td>m0</td>\n",
       "      <td>I missed you.</td>\n",
       "      <td>It says here you exposed yourself to a group o...</td>\n",
       "      <td>i missed you</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L60</td>\n",
       "      <td>u8</td>\n",
       "      <td>m0</td>\n",
       "      <td>It says here you exposed yourself to a group o...</td>\n",
       "      <td>It was a bratwurst. I was eating lunch.</td>\n",
       "      <td>it say here you exposed yourself to a group of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  msg_line user_id movie_id  \\\n",
       "0      L49      u0       m0   \n",
       "1      L50      u3       m0   \n",
       "2      L51      u0       m0   \n",
       "3      L59      u9       m0   \n",
       "4      L60      u8       m0   \n",
       "\n",
       "                                                 msg  \\\n",
       "0                          Did you change your hair?   \n",
       "1                                                No.   \n",
       "2                     You might wanna think about it   \n",
       "3                                      I missed you.   \n",
       "4  It says here you exposed yourself to a group o...   \n",
       "\n",
       "                                               msg_2  \\\n",
       "0                                                No.   \n",
       "1                     You might wanna think about it   \n",
       "2                                           maybe...   \n",
       "3  It says here you exposed yourself to a group o...   \n",
       "4            It was a bratwurst. I was eating lunch.   \n",
       "\n",
       "                                   msg_pre_processed  target  \n",
       "0                           did you change your hair       1  \n",
       "1                                                 no       0  \n",
       "2                     you might wanna think about it       0  \n",
       "3                                       i missed you       0  \n",
       "4  it say here you exposed yourself to a group of...       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4m4MaUd6-uwp"
   },
   "source": [
    "### Processing for deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "63E59l8g-uw0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257095\n"
     ]
    }
   ],
   "source": [
    "#setting the sample data for tests\n",
    "i = 0\n",
    "#n = 20000\n",
    "n = len(list(messages.index))\n",
    "print(str(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BOMZTuOE-uw5"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(messages['msg_pre_processed'][i:n].astype(str), messages['target'][i:n].astype(str), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cUoQCBFQ-uw9"
   },
   "outputs": [],
   "source": [
    "#dataframe with sample X and y\n",
    "df_small = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "L2jt59zU-uxA"
   },
   "outputs": [],
   "source": [
    "df_small['msg'] = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "MeU7MsGf-uxK"
   },
   "outputs": [],
   "source": [
    "df_small['target'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70522</th>\n",
       "      <td>and the people here don't want u are you kiddi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255135</th>\n",
       "      <td>you need a table</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93689</th>\n",
       "      <td>you asked me to model remember</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165248</th>\n",
       "      <td>pete have a brother</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249995</th>\n",
       "      <td>we wish to commune with the spirit of mr feur ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      msg target\n",
       "70522   and the people here don't want u are you kiddi...      1\n",
       "255135                                   you need a table      0\n",
       "93689                      you asked me to model remember      1\n",
       "165248                                pete have a brother      1\n",
       "249995  we wish to commune with the spirit of mr feur ...      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172253, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "axU_KyhD-uxO"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "# fit the tokenizer on the documents\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RW7GzloxvSRu",
    "outputId": "115c5c82-fa02-411c-feb4-60165e82249b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70522     and the people here don't want u are you kiddi...\n",
       "255135                                     you need a table\n",
       "93689                        you asked me to model remember\n",
       "165248                                  pete have a brother\n",
       "249995    we wish to commune with the spirit of mr feur ...\n",
       "                                ...                        \n",
       "119879                          we are don't worry about it\n",
       "103694              do you think there is any life up there\n",
       "131932    miss windham can you tell u what you'd been do...\n",
       "146867                                   detective crockett\n",
       "121958    in the city it happened all the time some kid ...\n",
       "Name: msg_pre_processed, Length: 172253, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70522     1\n",
       "255135    0\n",
       "93689     1\n",
       "165248    1\n",
       "249995    1\n",
       "         ..\n",
       "119879    0\n",
       "103694    1\n",
       "131932    1\n",
       "146867    0\n",
       "121958    1\n",
       "Name: target, Length: 172253, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "6yg81Oaw-uxU"
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 52.3 GiB for an array with shape (172253, 40761) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-21a4ee570da7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# encode training data set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras_preprocessing/text.py\u001b[0m in \u001b[0;36mtexts_to_matrix\u001b[0;34m(self, texts, mode)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \"\"\"\n\u001b[1;32m    382\u001b[0m         \u001b[0msequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences_to_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msequences_to_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras_preprocessing/text.py\u001b[0m in \u001b[0;36msequences_to_matrix\u001b[0;34m(self, sequences, mode)\u001b[0m\n\u001b[1;32m    411\u001b[0m                              'before using tfidf mode.')\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 52.3 GiB for an array with shape (172253, 40761) and data type float64"
     ]
    }
   ],
   "source": [
    "# encode training data set\n",
    "X_train_token = tokenizer.texts_to_matrix(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0R3fS3_M1M8b",
    "outputId": "cfecb0b1-184a-4a95-f6a3-c86082ebfdd8"
   },
   "outputs": [],
   "source": [
    "X_train_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6o_hnoSlyPCC",
    "outputId": "514222d8-da1b-4ccf-89d6-fc2220d2cdeb"
   },
   "outputs": [],
   "source": [
    "X_train_token.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IfbFpgVb-uxY"
   },
   "outputs": [],
   "source": [
    "#set the number of rows of X_train\n",
    "num_rows, num_cols = X_train_token.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dDgioaKkoVss",
    "outputId": "3a81feed-6bdc-4663-e128-e36297f99efd"
   },
   "outputs": [],
   "source": [
    "classes = set(df_small['target'])\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small['target'] = df_small['target'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "g-kOJzqlLpRh",
    "outputId": "c1671940-a155-40eb-8f58-779817ebdffe"
   },
   "outputs": [],
   "source": [
    "df_small.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAc01igYZJfe"
   },
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xFgmGR9f-uxv",
    "outputId": "ec3c427f-69f9-48f2-f7b6-629d4f521c8f"
   },
   "outputs": [],
   "source": [
    "# Create model - 3 layers. First layer 128 neurons, second layer 64 neurons and 3rd output layer contains number of neurons\n",
    "# equal to number of intents to predict output intent with softmax\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=num_cols, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DdnwUEvW-ux1",
    "outputId": "727d8923-cd40-4503-e88b-0999565761ad"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=False)\n",
    "model.compile(loss='BinaryCrossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "#fitting and saving the model\n",
    "hist = model.fit(X_train_token, df_small['target'], epochs=10, batch_size=20, verbose=1)\n",
    "model.save('chatbot_model.h5', hist)\n",
    "\n",
    "print(\"model created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUj8MLGpGmpl"
   },
   "source": [
    "### Testing the prototipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def pre_processing_text(corpus):   \n",
    "    #remove duplicated spaces\n",
    "    corpus = re.sub(r' +', ' ', corpus)\n",
    "    \n",
    "    #capitalization\n",
    "    corpus = corpus.lower()\n",
    "    \n",
    "    #tokenization\n",
    "    corpus = re.findall(r\"\\w+(?:'\\w+)?|[^\\w\\s]\", corpus)\n",
    "    \n",
    "    #lammatization\n",
    "    corpus = [lemmatizer.lemmatize(c) for c in corpus]\n",
    "    \n",
    "    #remove punctuation\n",
    "    corpus = [t for t in corpus if t not in string.punctuation]\n",
    "    \n",
    "    #remove stopwords\n",
    "    #it makes the model worst\n",
    "    #stopwords_ = stopwords.words(\"english\")\n",
    "    #corpus = [t for t in corpus if t not in stopwords_]\n",
    "    \n",
    "    corpus = ' '.join(corpus)\n",
    "\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_raw = 'I heard you are a good guy. Is it right?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = pre_processing_text(msg_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S1zQZgEu-ux7"
   },
   "outputs": [],
   "source": [
    "p = tokenizer.texts_to_matrix([msg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PQ3tlzOFvBqs",
    "outputId": "8bc89fcd-78b9-40c1-835a-2e0de5a21d16"
   },
   "outputs": [],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ukmWl_6h-uyE"
   },
   "outputs": [],
   "source": [
    "res = model.predict(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vB5caYtk-uyJ",
    "outputId": "c029790d-5746-4119-ab0e-3f34c0d886f4"
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the list of questions and answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s0r76sH8-uy9"
   },
   "outputs": [],
   "source": [
    "questions = set(df_small[df_small['target'] == 1]['msg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = set(df_small[df_small['target'] == 0]['msg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returning the conversation for the message using Jaccard Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(f1, f2):\n",
    "    f1 = set(f1)\n",
    "    f2 = set(f2)\n",
    "    \n",
    "    intersecao = f1.intersection(f2)\n",
    "    uniao = f1.union(f2)\n",
    "    \n",
    "    return len(intersecao) / len(uniao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_conversation_by_jaccard(msg, res, questions, answers):\n",
    "    \"\"\"\n",
    "    Return a dictionary of message and similarity sorted by highter similarity\n",
    "    \"\"\"\n",
    "    if res >= 0.5:\n",
    "        msg_list = questions\n",
    "        similarity = [jaccard_similarity(msg, m) for m in questions]     \n",
    "    else:\n",
    "        similarity = [jaccard_similarity(msg, m) for m in answers]\n",
    "        msg_list = answers\n",
    "    \n",
    "    result = {} \n",
    "    for key in msg_list: \n",
    "        for value in similarity: \n",
    "            result[key] = value\n",
    "            similarity.remove(value) \n",
    "            break \n",
    "    \n",
    "    return {k: v for k, v in sorted(result.items(), key=lambda item: item[1], reverse=True)}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UUjgakfd-uzQ"
   },
   "outputs": [],
   "source": [
    "conversations = return_conversation_by_jaccard(msg, res, questions, answers)\n",
    "conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the first item in the dict\n",
    "def get_the_next_conversation(conversations):\n",
    "    keys_view = conversations.keys()\n",
    "    keys_iterator = iter(keys_view)\n",
    "    conversation = next(keys_iterator)\n",
    "    return conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = get_the_next_conversation(conversations)\n",
    "conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The returned message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('>>> '+msg_raw)\n",
    "msg2 = list(messages[messages['msg_pre_processed'] == conversation]['msg_2'])[0]\n",
    "print('<<< '+msg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return the result using the Cossine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_conversation_by_cossine(msg, res, questions, answers, bow):\n",
    "    \"\"\"\n",
    "    Return a dictionary of message and similarity sorted by highter similarity\n",
    "    \"\"\"\n",
    "    if res >= 0.5:\n",
    "        msg_list = questions    \n",
    "    else:\n",
    "        msg_list = answers\n",
    "       \n",
    "    similarity = []\n",
    "    for m in msg_list:\n",
    "        new_msg_list = [msg, m]\n",
    "        vector_bow = bow.fit_transform(new_msg_list)\n",
    "        msg_bow = vector_bow.todense()[0]\n",
    "        m_bow   = vector_bow.todense()[1]\n",
    "        similarity.append(distance.cosine(msg_bow, m_bow))\n",
    "    \n",
    "    result = {} \n",
    "    for key in msg_list: \n",
    "        for value in similarity: \n",
    "            result[key] = value\n",
    "            similarity.remove(value) \n",
    "            break \n",
    "    \n",
    "    return {k: v for k, v in sorted(result.items(), key=lambda item: item[1], reverse=False)}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations = return_conversation_by_cossine(msg, res, questions, answers, bow)\n",
    "conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = get_the_next_conversation(conversations)\n",
    "conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('>>> '+msg_raw)\n",
    "msg2 = list(messages[messages['msg_pre_processed'] == conversation]['msg_2'])[0]\n",
    "print('<<< '+msg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get result using Cossine Similarity with Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_embedding(get_it):\n",
    "    if get_it:\n",
    "        !gdown https://drive.google.com/uc?id=1zI8pGfbUHuU_0wY_FV4tD6w6ZCUJTQbh\n",
    "    print('Download finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The embedding is already downloaded\n",
    "#Change to True to download\n",
    "download_embedding(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#get the embedding\n",
    "newfilepath = \"embedding_wiki_100d_pt.txt\"\n",
    "filepath = \"ptwiki_20180420_100d.txt.bz2\"\n",
    "with open(newfilepath, 'wb') as new_file, bz2.BZ2File(filepath, 'rb') as file:\n",
    "    for data in iter(lambda : file.read(100 * 1024), b''):\n",
    "        new_file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "word_vectors = gensim.models.KeyedVectors.load_word2vec_format(filepath, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_embedding(phrase):\n",
    "    \"\"\"\n",
    "    Return the mean of embeddings of a phrase\n",
    "    \"\"\"\n",
    "    \n",
    "    arr = np.array([word_vectors[word] for word in phrase if word in word_vectors.vocab])\n",
    "    \n",
    "    sum = np.zeros(len(arr[0]))\n",
    "    for a in arr:\n",
    "        sum = sum + a\n",
    "        \n",
    "    arr_mean = sum / len(arr) \n",
    "    \n",
    "    return arr_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_conversation_by_cossine_embedding(msg, res, questions, answers, word_vectors):\n",
    "    \"\"\"\n",
    "    Return a dictionary of message and similarity sorted by highter similarity\n",
    "    \"\"\"\n",
    "    if res >= 0.5:\n",
    "        msg_list = questions    \n",
    "    else:\n",
    "        msg_list = answers       \n",
    "    \n",
    "    msg = msg.split(' ')\n",
    "    \n",
    "    similarity = []\n",
    "    for m in msg_list:        \n",
    "        m = m.split(' ')\n",
    "        \n",
    "        try:\n",
    "            msg_vector_embedding = calculate_embedding(msg)\n",
    "            m_vector_embedding   = calculate_embedding(m)\n",
    "        \n",
    "            similarity.append(distance.cosine(msg_vector_embedding, m_vector_embedding))\n",
    "        except:\n",
    "            print(\"An exception occurred\")\n",
    "            print('> '+ ' '.join(m))\n",
    "    \n",
    "    result = {} \n",
    "    for key in msg_list: \n",
    "        for value in similarity: \n",
    "            result[key] = value\n",
    "            similarity.remove(value) \n",
    "            break \n",
    "    \n",
    "    return {k: v for k, v in sorted(result.items(), key=lambda item: item[1], reverse=False)}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "conversations = return_conversation_by_cossine_embedding(msg, res, questions, answers, word_vectors)\n",
    "conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = get_the_next_conversation(conversations)\n",
    "conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('>>> '+msg_raw)\n",
    "msg2 = list(messages[messages['msg_pre_processed'] == conversation]['msg_2'])[0]\n",
    "print('<<< '+msg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "TF - Chatbot-protptipo-v2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
