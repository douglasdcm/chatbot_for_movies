{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-BSEigEE-utQ"
   },
   "source": [
    "## Pre-processamento do dataset para alimentar a rede neural keras para classificação de perguntas (1) e respostas (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AgR-ezT5-utZ",
    "outputId": "f773f454-e438-42fd-81a2-70b325be7745"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Um5L0h0-utn"
   },
   "source": [
    "### Opening movie reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Crtu4lkNCvuE"
   },
   "outputs": [],
   "source": [
    "messages = pd.read_csv('./chatdata/movie_lines_normalized.tsv', header = None, delimiter=\"\\t\", quoting=3, encoding='ISO-8859-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_C-PgIGR-uuF"
   },
   "outputs": [],
   "source": [
    "messages.columns = ['msg_line', 'user_id', 'movie_id', 'msg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "id": "lPpD5i2O-ut8",
    "outputId": "5652b189-b4d8-41c2-9d25-672498bd921f"
   },
   "outputs": [],
   "source": [
    "messages.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suw3SOJl-uuF"
   },
   "source": [
    "### Cleaning the msg_line of the conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FqD3IJCq-uuL"
   },
   "outputs": [],
   "source": [
    "#remove charactes\n",
    "def remove_char(txt):\n",
    "    return re.sub('[^0-9]','', txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MnwDRnuj-uuR"
   },
   "outputs": [],
   "source": [
    "#leaving just the number of the index, so L872 changes to 872\n",
    "messages['msg_line_clean'] = [remove_char(msg) for msg in messages['msg_line']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lxO3JxI7-uuk"
   },
   "outputs": [],
   "source": [
    "#change the column type to number\n",
    "messages['msg_line_clean'] = pd.to_numeric(messages['msg_line_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "PoOMsQQM-uuY",
    "outputId": "9a66c998-73dd-4b66-b1d8-b31685525a41"
   },
   "outputs": [],
   "source": [
    "messages = messages.sort_values(by=['msg_line_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VoBhDvuC-uu_"
   },
   "outputs": [],
   "source": [
    "#set the column as the index\n",
    "messages = messages.set_index('msg_line_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 378
    },
    "id": "jdUesfac-uvI",
    "outputId": "5d9e7d94-20f1-4258-b51e-5581d0668930"
   },
   "outputs": [],
   "source": [
    "messages.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = pd.read_csv('./chatdata/entity_list_complete.tsv', header = None, delimiter=\"\\t\", quoting=3, encoding='ISO-8859-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities.columns = ['ent', 'type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities['ent'] = entities['ent'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities['ent_len'] = [len(e) for e in entities['ent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = entities['ent_len'].sort_values(ascending=False).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = entities.reindex(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = entities.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = messages['msg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_list =  ['PERSON', 'ORG', 'NORP', 'FAC', 'GPE', 'LOC', 'PRODUCT', 'EVENT', 'WORK_OF_ART', 'LAW', 'LANGUAGE']\n",
    "#ent_list =  ['LANGUAGE']\n",
    "\n",
    "ent = list()\n",
    "for i in range(len(entities.index)):\n",
    "    if entities['type'][i] in ent_list:\n",
    "        ent.append(entities['ent'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent = list(set(ent))\n",
    "print(len(ent))\n",
    "print(ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {}\n",
    "for n in ent:\n",
    "    dict[n] = len(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort dict by biggest values\n",
    "dict = {k: v for k, v in sorted(dict.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_entity(corpus):\n",
    "    corpus = corpus.split(' ')\n",
    "    corpus = [c for c in corpus if c not in list(dict.keys())]\n",
    "    return ' '.join(corpus)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "messages['msg_pre_processed'] = [remove_entity(m) for m in list(data)]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#chepoint\n",
    "messages.to_csv('./chatdata/movie_lines_pre_processed.tsv', index=False, sep='\\t', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mgQ0XkQ0-uvT"
   },
   "source": [
    "### Opening conversation sequence"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "j9UdxwDA-uvV"
   },
   "source": [
    "#read the file with the conversation sequence\n",
    "conv_seq = pd.read_csv('./chatdata/movie_conversations.tsv', header = None, delimiter=\"\\t\", quoting=3, encoding='ISO-8859-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SD-sm3ct-uvl"
   },
   "outputs": [],
   "source": [
    "conv_seq.columns = ['user1_id', 'user2_id', 'movie_id', 'sequence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "id": "BNv6rvyk-uve",
    "outputId": "892bc640-0b14-4edc-93b2-b3a69b8af16f"
   },
   "outputs": [],
   "source": [
    "conv_seq.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-lscQ_z-uvz"
   },
   "source": [
    "### Build conversation sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MdH5_-1J-uv1"
   },
   "outputs": [],
   "source": [
    "def split_conversation(txt):\n",
    "    txt_alt = txt.split(' ')\n",
    "    return txt_alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_725CFTF-uv5"
   },
   "outputs": [],
   "source": [
    "def seq_to_list(seq):\n",
    "    seq_list = [remove_char(s) for s in seq]\n",
    "    return seq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96GzaYvK-uwE"
   },
   "outputs": [],
   "source": [
    "#initializing the msg_2 column\n",
    "messages['msg_2'] = '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "63L_vxvm-uwJ"
   },
   "outputs": [],
   "source": [
    "def link_conversations(seq_list, df, filter1, filter2):\n",
    "    i = 0\n",
    "    while i in range(len(seq_list)):\n",
    "        if i+1 < len(seq_list):\n",
    "            next_msg = df.loc[int(seq_list[i+1]), filter1]\n",
    "            df.at[int(seq_list[i]), filter2] = next_msg\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "feAL4Y-5-uwd"
   },
   "outputs": [],
   "source": [
    "#link each message with its answer\n",
    "for conv in conv_seq['sequence']:\n",
    "    #split each sequence by space\n",
    "    seq = split_conversation(conv)\n",
    "\n",
    "    #remove the char L from the sequences\n",
    "    txt_alt = [remove_char(s) for s in seq]\n",
    "\n",
    "    #use the conversation sequence to build the target answer for each message\n",
    "    link_conversations(txt_alt, messages, 'msg', 'msg_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 978
    },
    "id": "63uZAAbm-uwk",
    "outputId": "4eff9982-1533-471d-e7d8-f003283d8572"
   },
   "outputs": [],
   "source": [
    "messages.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre processing the msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = messages['msg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def pre_processing_text(corpus):\n",
    "    #remove html tags\n",
    "    corpus = re.sub(r'<.*?>', '', str(corpus))\n",
    "    \n",
    "    #remove non-alphanumeric characters\n",
    "    corpus = re.sub(r'[^a-z A-Z 0-9 \\s]', '', str(corpus))\n",
    "    \n",
    "    #remove duplicated spaces\n",
    "    corpus = re.sub(r' +', ' ', str(corpus))\n",
    "    \n",
    "    #capitalization\n",
    "    corpus = corpus.lower()\n",
    "    \n",
    "    #tokenization\n",
    "    corpus = re.findall(r\"\\w+(?:'\\w+)?|[^\\w\\s]\", corpus)\n",
    "    \n",
    "    #lammatization\n",
    "    corpus = [lemmatizer.lemmatize(c) for c in corpus]\n",
    "    \n",
    "    #remove punctuation\n",
    "    corpus = [t for t in corpus if t not in string.punctuation]\n",
    "    \n",
    "    #remove stopwords\n",
    "    #it makes the model worst\n",
    "    #stopwords_ = stopwords.words(\"english\")\n",
    "    #corpus = [t for t in corpus if t not in stopwords_]\n",
    "    \n",
    "    corpus = ' '.join(corpus)\n",
    "\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data_pre_processed = [pre_processing_text(str(m)) for m in data]\n",
    "data_pre_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['msg_pre_processed'] = data_pre_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking and removing duplicated messages in msg (not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = messages['msg_pre_processed']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dict = {}\n",
    "for n in data:\n",
    "    if n in dict:\n",
    "        dict[n] = dict[n] + 1\n",
    "    else:\n",
    "        dict[n] = 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#sort dict by biggest values\n",
    "dict = {k: v for k, v in sorted(dict.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dict"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#example of duplcated msg\n",
    "messages[messages['msg_pre_processed'] == 'did you change your hair']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#get the repeated messages\n",
    "d_list = list()\n",
    "for k in dict:\n",
    "    if dict[k] > 1:\n",
    "        d_list.append(k)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "d_list"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "messages = messages.drop_duplicates(subset=['msg_pre_processed'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#example of duplcated msg\n",
    "messages[messages['msg_pre_processed'] == 'did you change your hair']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing nan msg origined by '' messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling the nan messages with a string- not necessary\n",
    "#messages = messages.fillna('UNKNOWN')\n",
    "messages = messages.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing apostrophes (need for embedding) (not used)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#The quality of the model became worst\n",
    "messages['msg_pre_processed'] = [ word.replace(\"\\'\",\"\") for word in messages['msg_pre_processed']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling '-' messages with a generic one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mtY7k0fdfm3Q"
   },
   "outputs": [],
   "source": [
    "#return generic answer\n",
    "def generic_answer(txt):\n",
    "  asw_list = ['talk more about it',\n",
    "              'can you explain it better?',\n",
    "              'I need to think more about it',\n",
    "              'maybe...'\n",
    "              ]\n",
    "  if txt == '-':\n",
    "    return random.choice(asw_list)\n",
    "  return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sMF4FXzJhFaB"
   },
   "outputs": [],
   "source": [
    "#seting a generic answer to the messages without answer\n",
    "messages['msg_2'] = [generic_answer(msg) for msg in messages['msg_2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging the msg with classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_target(corpus):\n",
    "    \n",
    "    if '?' in corpus:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = messages['msg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['target'] = [define_target(m) for m in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['target'] = messages['target'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.to_csv('./chatdata/movie_lines_pre_processed_keras.tsv', index=False, sep='\\t', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "TF - Chatbot-protptipo-v2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
