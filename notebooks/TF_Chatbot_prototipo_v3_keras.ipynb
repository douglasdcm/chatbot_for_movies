{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-BSEigEE-utQ"
   },
   "source": [
    "## A intenção do projeto é criar um chatbot baseado em reviews de filmes para que se possa fazer perguntas e manter uma conversa livre sobre este tema\n",
    "\n",
    "- link do banco de dados https://www.kaggle.com/Cornell-University/movie-dialog-corpus?select=movie_lines.tsv\n",
    "- referências\n",
    ">- https://shanebarker.com/blog/deep-learning-chatbot/\n",
    "> -https://towardsdatascience.com/how-to-create-a-chatbot-with-python-deep-learning-in-less-than-an-hour-56a063bdfc44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AgR-ezT5-utZ",
    "outputId": "f773f454-e438-42fd-81a2-70b325be7745"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/douglas/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import re\n",
    "import gensim\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from scipy.spatial import distance\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import random\n",
    "import bz2\n",
    "import itertools\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#expand jupyter cells\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Um5L0h0-utn"
   },
   "source": [
    "### Opening movie reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "id": "Crtu4lkNCvuE"
   },
   "outputs": [],
   "source": [
    "messages = pd.read_csv('./chatdata/movie_lines_pre_processed.tsv', delimiter=\"\\t\", quoting=3, encoding='ISO-8859-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg_line</th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>msg</th>\n",
       "      <th>msg_2</th>\n",
       "      <th>msg_pre_processed</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L49</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>Did you change your hair?</td>\n",
       "      <td>No.</td>\n",
       "      <td>you change your hair</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L50</td>\n",
       "      <td>u3</td>\n",
       "      <td>m0</td>\n",
       "      <td>No.</td>\n",
       "      <td>You might think about it</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L51</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>You might wanna think about it</td>\n",
       "      <td>can you explain it better?</td>\n",
       "      <td>you might think about it</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L59</td>\n",
       "      <td>u9</td>\n",
       "      <td>m0</td>\n",
       "      <td>I missed you.</td>\n",
       "      <td>It says here you exposed yourself to a group o...</td>\n",
       "      <td>i missed you</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L60</td>\n",
       "      <td>u8</td>\n",
       "      <td>m0</td>\n",
       "      <td>It says here you exposed yourself to a group o...</td>\n",
       "      <td>It was a bratwurst. I was eating lunch.</td>\n",
       "      <td>it say here you exposed yourself to a group of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  msg_line user_id movie_id  \\\n",
       "0      L49      u0       m0   \n",
       "1      L50      u3       m0   \n",
       "2      L51      u0       m0   \n",
       "3      L59      u9       m0   \n",
       "4      L60      u8       m0   \n",
       "\n",
       "                                                 msg  \\\n",
       "0                          Did you change your hair?   \n",
       "1                                                No.   \n",
       "2                     You might wanna think about it   \n",
       "3                                      I missed you.   \n",
       "4  It says here you exposed yourself to a group o...   \n",
       "\n",
       "                                               msg_2  \\\n",
       "0                                                No.   \n",
       "1                           You might think about it   \n",
       "2                         can you explain it better?   \n",
       "3  It says here you exposed yourself to a group o...   \n",
       "4            It was a bratwurst. I was eating lunch.   \n",
       "\n",
       "                                   msg_pre_processed  target  \n",
       "0                               you change your hair       1  \n",
       "1                                                 no       0  \n",
       "2                           you might think about it       0  \n",
       "3                                       i missed you       0  \n",
       "4  it say here you exposed yourself to a group of...       0  "
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4m4MaUd6-uwp"
   },
   "source": [
    "### Processing for deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "id": "63E59l8g-uw0"
   },
   "outputs": [],
   "source": [
    "#setting the sample data for tests\n",
    "i = 0\n",
    "n = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "id": "BOMZTuOE-uw5"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(messages['msg_pre_processed'][i:n].astype(str), messages['target'][i:n].astype(str), test_size=0.33, stratify=messages['target'][i:n], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "id": "cUoQCBFQ-uw9"
   },
   "outputs": [],
   "source": [
    "#dataframe with sample X and y\n",
    "df_small = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "id": "L2jt59zU-uxA"
   },
   "outputs": [],
   "source": [
    "df_small['msg_pre_processed'] = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "id": "MeU7MsGf-uxK"
   },
   "outputs": [],
   "source": [
    "df_small['target'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg_pre_processed</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6272</th>\n",
       "      <td>switchboard how may i direct your call</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>i cant date her sister until that one get a bo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16688</th>\n",
       "      <td>evening baxter</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16365</th>\n",
       "      <td>general the severe food shortage that face the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6940</th>\n",
       "      <td>no im all alone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       msg_pre_processed target\n",
       "6272              switchboard how may i direct your call      0\n",
       "159    i cant date her sister until that one get a bo...      0\n",
       "16688                                     evening baxter      0\n",
       "16365  general the severe food shortage that face the...      1\n",
       "6940                                     no im all alone      0"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13400, 2)"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "id": "axU_KyhD-uxO"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "# fit the tokenizer on the documents\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# saving\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RW7GzloxvSRu",
    "outputId": "115c5c82-fa02-411c-feb4-60165e82249b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6272                switchboard how may i direct your call\n",
       "159      i cant date her sister until that one get a bo...\n",
       "16688                                       evening baxter\n",
       "16365    general the severe food shortage that face the...\n",
       "6940                                       no im all alone\n",
       "                               ...                        \n",
       "2434                     she dropped in on me holding this\n",
       "5487                                         saying did it\n",
       "11969                                that wa a great night\n",
       "11056                               not far enough come on\n",
       "10839            of course now away before i get any older\n",
       "Name: msg_pre_processed, Length: 13400, dtype: object"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6272     0\n",
       "159      0\n",
       "16688    0\n",
       "16365    1\n",
       "6940     0\n",
       "        ..\n",
       "2434     0\n",
       "5487     1\n",
       "11969    0\n",
       "11056    0\n",
       "10839    0\n",
       "Name: target, Length: 13400, dtype: object"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "id": "6yg81Oaw-uxU"
   },
   "outputs": [],
   "source": [
    "# encode training data set\n",
    "X_train_token = tokenizer.texts_to_matrix(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0R3fS3_M1M8b",
    "outputId": "cfecb0b1-184a-4a95-f6a3-c86082ebfdd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6o_hnoSlyPCC",
    "outputId": "514222d8-da1b-4ccf-89d6-fc2220d2cdeb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13400, 9805)"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_token.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "id": "IfbFpgVb-uxY"
   },
   "outputs": [],
   "source": [
    "#set the number of rows of X_train\n",
    "num_rows, num_cols = X_train_token.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dDgioaKkoVss",
    "outputId": "3a81feed-6bdc-4663-e128-e36297f99efd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0', '1'}"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = set(df_small['target'])\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small['target'] = df_small['target'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "g-kOJzqlLpRh",
    "outputId": "c1671940-a155-40eb-8f58-779817ebdffe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg_pre_processed</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6272</th>\n",
       "      <td>switchboard how may i direct your call</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>i cant date her sister until that one get a bo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16688</th>\n",
       "      <td>evening baxter</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16365</th>\n",
       "      <td>general the severe food shortage that face the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6940</th>\n",
       "      <td>no im all alone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       msg_pre_processed  target\n",
       "6272              switchboard how may i direct your call       0\n",
       "159    i cant date her sister until that one get a bo...       0\n",
       "16688                                     evening baxter       0\n",
       "16365  general the severe food shortage that face the...       1\n",
       "6940                                     no im all alone       0"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for the best parameters"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def create_model(X, y, activation='relu', momentum=0.9, learn_rate=0.01, decay=1e-6,\n",
    "                 dropout_rate=0.5, weight_constraint=1, neurons=20, init='uniform',\n",
    "                 optimizer='SGD', nesterov=False, num_cols=10, pos_fix='',\n",
    "                 epochs=10, validation_split=0.3, batch_size=20):\n",
    "        \n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim=num_cols, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons/2, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    #model.summary()\n",
    "    \n",
    "    # Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
    "    sgd = SGD(lr=learn_rate, decay=decay, momentum=momentum, nesterov=nesterov)\n",
    "    model.compile(loss='BinaryCrossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "    callbacks = [EarlyStopping(monitor='val_accuracy', patience=3, verbose=0),\n",
    "                tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),]\n",
    "    \n",
    "    hist = model.fit(X, y, epochs=epochs, validation_split=validation_split, batch_size=batch_size, verbose=1, callbacks=callbacks)\n",
    "    \n",
    "    model_name = './models/chatbot_model_'+ pos_fix +'_.h5'\n",
    "    #model.save(model_name, hist)\n",
    "\n",
    "    print('model '+ model_name +' created')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "#cross-validation - cell not-used anymore\n",
    "\n",
    "#This seasch must to be done due an isse with Kears and GridSearch\n",
    "#    ERROR: can't pickle _thread.RLock objects\n",
    "\n",
    "\n",
    "params = {\n",
    "    'activation': ['relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],\n",
    "    'momentum': [0.5, 0.9],\n",
    "    'learn_rate': [0.0001, 0.001],\n",
    "    'dropout_rate': [0.5, 0.8],\n",
    "    'neurons': [210, 500],\n",
    "    'epochs': [210],\n",
    "    'batch_size': [20, 40, 60, 100],\n",
    "    'decay': [1e-6, 1e-5, 1e-4, 1e-3],\n",
    "    'nesterov': [False, True]\n",
    "    }\n",
    "\n",
    "keys = list(params)\n",
    "i = 0\n",
    "for values in itertools.product(*map(params.get, keys)):\n",
    "    print(dict(zip(keys, values)))\n",
    "    model = create_model(**dict(zip(keys, values)), X=X_train_token, y=df_small['target'], num_cols=num_cols, pos_fix=str(i))\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAc01igYZJfe"
   },
   "source": [
    "### Training the model with fixed parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xFgmGR9f-uxv",
    "outputId": "ec3c427f-69f9-48f2-f7b6-629d4f521c8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 20)                196120    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 196,341\n",
      "Trainable params: 196,341\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model - 3 layers. First layer 128 neurons, second layer 64 neurons and 3rd output layer contains number of neurons\n",
    "# equal to number of intents to predict output intent with softmax\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=num_cols, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.6 ms, sys: 15.6 ms, total: 31.2 ms\n",
      "Wall time: 39.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=False)\n",
    "model.compile(loss='BinaryCrossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DdnwUEvW-ux1",
    "outputId": "727d8923-cd40-4503-e88b-0999565761ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.5978 - accuracy: 0.7010 - val_loss: 0.5160 - val_accuracy: 0.7736\n",
      "Epoch 2/500\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.5417 - accuracy: 0.7484 - val_loss: 0.4853 - val_accuracy: 0.7823\n",
      "Epoch 3/500\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.5191 - accuracy: 0.7640 - val_loss: 0.4639 - val_accuracy: 0.7980\n",
      "Epoch 4/500\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.4995 - accuracy: 0.7763 - val_loss: 0.4654 - val_accuracy: 0.7948\n",
      "Epoch 5/500\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.4806 - accuracy: 0.7854 - val_loss: 0.4623 - val_accuracy: 0.7935\n",
      "Epoch 6/500\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4731 - accuracy: 0.7873 - val_loss: 0.4555 - val_accuracy: 0.7995\n",
      "Epoch 7/500\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4615 - accuracy: 0.7974 - val_loss: 0.4581 - val_accuracy: 0.8017\n",
      "Epoch 8/500\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4484 - accuracy: 0.8039 - val_loss: 0.4556 - val_accuracy: 0.8000\n",
      "Epoch 9/500\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4381 - accuracy: 0.8098 - val_loss: 0.4608 - val_accuracy: 0.7985\n",
      "Epoch 10/500\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4264 - accuracy: 0.8135 - val_loss: 0.4603 - val_accuracy: 0.8015\n",
      "Epoch 11/500\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4141 - accuracy: 0.8228 - val_loss: 0.4556 - val_accuracy: 0.8020\n",
      "Epoch 12/500\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4072 - accuracy: 0.8224 - val_loss: 0.4623 - val_accuracy: 0.8000\n",
      "Epoch 13/500\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4009 - accuracy: 0.8296 - val_loss: 0.4867 - val_accuracy: 0.7988\n",
      "Epoch 14/500\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3963 - accuracy: 0.8286 - val_loss: 0.4652 - val_accuracy: 0.8010\n",
      "Epoch 15/500\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3830 - accuracy: 0.8352 - val_loss: 0.4755 - val_accuracy: 0.8040\n",
      "Epoch 16/500\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3681 - accuracy: 0.8462 - val_loss: 0.4747 - val_accuracy: 0.8002\n",
      "Epoch 17/500\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3640 - accuracy: 0.8481 - val_loss: 0.4745 - val_accuracy: 0.7975\n",
      "Epoch 18/500\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3651 - accuracy: 0.8448 - val_loss: 0.4744 - val_accuracy: 0.8022\n",
      "Epoch 19/500\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3576 - accuracy: 0.8438 - val_loss: 0.4944 - val_accuracy: 0.8027\n",
      "Epoch 20/500\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3370 - accuracy: 0.8586 - val_loss: 0.4968 - val_accuracy: 0.7965\n",
      "Epoch 21/500\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3480 - accuracy: 0.8549 - val_loss: 0.4875 - val_accuracy: 0.7998\n",
      "Epoch 22/500\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3296 - accuracy: 0.8627 - val_loss: 0.5351 - val_accuracy: 0.7998\n",
      "Epoch 23/500\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3252 - accuracy: 0.8624 - val_loss: 0.5010 - val_accuracy: 0.7978\n",
      "Epoch 24/500\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3209 - accuracy: 0.8684 - val_loss: 0.5241 - val_accuracy: 0.8030\n",
      "Epoch 25/500\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3194 - accuracy: 0.8651 - val_loss: 0.5485 - val_accuracy: 0.7970\n",
      "model created\n",
      "CPU times: user 1min 33s, sys: 11.5 s, total: 1min 45s\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_accuracy', patience=10, verbose=0),\n",
    "                ModelCheckpoint(filepath='model.{epoch:02d}-{val_accuracy:.2f}.h5'),\n",
    "            ]\n",
    "\n",
    "#fitting and saving the model\n",
    "hist = model.fit(X_train_token, df_small['target'], epochs=500, validation_split=0.3, batch_size=20, verbose=1, callbacks=callbacks)\n",
    "model.save('chatbot_model.h5', hist)\n",
    "\n",
    "print(\"model created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUj8MLGpGmpl"
   },
   "source": [
    "### Testing the prototipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = load_model('chatbot_model.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pre_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def pre_processing_text(corpus):\n",
    "    #remove html tags\n",
    "    corpus = re.sub(r'<.*?>', '', str(corpus))\n",
    "    \n",
    "    #remove non-alphanumeric characters\n",
    "    corpus = re.sub(r'[^a-z A-Z 0-9 \\s]', '', str(corpus))\n",
    "    \n",
    "    #remove duplicated spaces\n",
    "    corpus = re.sub(r' +', ' ', str(corpus))\n",
    "    \n",
    "    #capitalization\n",
    "    corpus = corpus.lower()\n",
    "    \n",
    "    #tokenization\n",
    "    corpus = re.findall(r\"\\w+(?:'\\w+)?|[^\\w\\s]\", corpus)\n",
    "    \n",
    "    #lammatization\n",
    "    corpus = [lemmatizer.lemmatize(c) for c in corpus]\n",
    "    \n",
    "    #remove punctuation\n",
    "    corpus = [t for t in corpus if t not in string.punctuation]\n",
    "    \n",
    "    #remove stopwords\n",
    "    #it makes the model worst\n",
    "    #stopwords_ = stopwords.words(\"english\")\n",
    "    #corpus = [t for t in corpus if t not in stopwords_]\n",
    "    \n",
    "    corpus = ' '.join(corpus)\n",
    "\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_raw = 'I heard you are a good guy. Is it right?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = pre_processing_text(msg_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "id": "S1zQZgEu-ux7"
   },
   "outputs": [],
   "source": [
    "p = tokenizer.texts_to_matrix([msg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PQ3tlzOFvBqs",
    "outputId": "8bc89fcd-78b9-40c1-835a-2e0de5a21d16"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 9805)"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "id": "ukmWl_6h-uyE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3734df80d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vB5caYtk-uyJ",
    "outputId": "c029790d-5746-4119-ab0e-3f34c0d886f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.79494965]], dtype=float32)"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "TF - Chatbot-protptipo-v2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
