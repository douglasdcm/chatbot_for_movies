{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-BSEigEE-utQ"
   },
   "source": [
    "## Treinamento da rede neural Keras para classificação de perguntas (1) e respostas (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AgR-ezT5-utZ",
    "outputId": "f773f454-e438-42fd-81a2-70b325be7745"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/douglas/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import re\n",
    "import gensim\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from scipy.spatial import distance\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import random\n",
    "import bz2\n",
    "import itertools\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#expand jupyter cells\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Um5L0h0-utn"
   },
   "source": [
    "### Opening movie reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "Crtu4lkNCvuE"
   },
   "outputs": [],
   "source": [
    "messages = pd.read_csv('./chatdata/movie_lines_pre_processed_keras.tsv', delimiter=\"\\t\", quoting=3, encoding='ISO-8859-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.columns = ['msg_line', 'user_id', 'movie_id', 'msg', 'msg_pre_processed', 'msg_2', 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg_line</th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>msg</th>\n",
       "      <th>msg_pre_processed</th>\n",
       "      <th>msg_2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L50</td>\n",
       "      <td>u3</td>\n",
       "      <td>m0</td>\n",
       "      <td>No.</td>\n",
       "      <td>no</td>\n",
       "      <td>You might wanna think about it</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L51</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>You might wanna think about it</td>\n",
       "      <td>you might wanna think about it</td>\n",
       "      <td>I need to think more about it</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L59</td>\n",
       "      <td>u9</td>\n",
       "      <td>m0</td>\n",
       "      <td>I missed you.</td>\n",
       "      <td>i missed you</td>\n",
       "      <td>It says here you exposed yourself to a group o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L60</td>\n",
       "      <td>u8</td>\n",
       "      <td>m0</td>\n",
       "      <td>It says here you exposed yourself to a group o...</td>\n",
       "      <td>it say here you exposed yourself to a group of...</td>\n",
       "      <td>It was a bratwurst. I was eating lunch.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L61</td>\n",
       "      <td>u9</td>\n",
       "      <td>m0</td>\n",
       "      <td>It was a bratwurst. I was eating lunch.</td>\n",
       "      <td>it wa a bratwurst i wa eating lunch</td>\n",
       "      <td>With the teeth of your zipper?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  msg_line user_id movie_id  \\\n",
       "0      L50      u3       m0   \n",
       "1      L51      u0       m0   \n",
       "2      L59      u9       m0   \n",
       "3      L60      u8       m0   \n",
       "4      L61      u9       m0   \n",
       "\n",
       "                                                 msg  \\\n",
       "0                                                No.   \n",
       "1                     You might wanna think about it   \n",
       "2                                      I missed you.   \n",
       "3  It says here you exposed yourself to a group o...   \n",
       "4            It was a bratwurst. I was eating lunch.   \n",
       "\n",
       "                                   msg_pre_processed  \\\n",
       "0                                                 no   \n",
       "1                     you might wanna think about it   \n",
       "2                                       i missed you   \n",
       "3  it say here you exposed yourself to a group of...   \n",
       "4                it wa a bratwurst i wa eating lunch   \n",
       "\n",
       "                                               msg_2  target  \n",
       "0                     You might wanna think about it       0  \n",
       "1                      I need to think more about it       0  \n",
       "2  It says here you exposed yourself to a group o...       0  \n",
       "3            It was a bratwurst. I was eating lunch.       0  \n",
       "4                     With the teeth of your zipper?       0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4m4MaUd6-uwp"
   },
   "source": [
    "### Processing for deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "63E59l8g-uw0"
   },
   "outputs": [],
   "source": [
    "#setting the sample data for tests\n",
    "i = 0\n",
    "n = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "BOMZTuOE-uw5"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(messages['msg_pre_processed'][i:n].astype(str), messages['target'][i:n].astype(str), test_size=0.33, stratify=messages['target'][i:n], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "cUoQCBFQ-uw9"
   },
   "outputs": [],
   "source": [
    "#dataframe with sample X and y\n",
    "df_small = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "L2jt59zU-uxA"
   },
   "outputs": [],
   "source": [
    "df_small['msg_pre_processed'] = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "MeU7MsGf-uxK"
   },
   "outputs": [],
   "source": [
    "df_small['target'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg_pre_processed</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17249</th>\n",
       "      <td>im ready</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10205</th>\n",
       "      <td>im a human being ive got some</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16875</th>\n",
       "      <td>ill say a little a possible</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16512</th>\n",
       "      <td>hey what is this you got black soap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>he doesnt speak english</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         msg_pre_processed target\n",
       "17249                             im ready      0\n",
       "10205        im a human being ive got some      0\n",
       "16875          ill say a little a possible      0\n",
       "16512  hey what is this you got black soap      1\n",
       "965                he doesnt speak english      0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13400, 2)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "axU_KyhD-uxO"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "# fit the tokenizer on the documents\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# saving\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RW7GzloxvSRu",
    "outputId": "115c5c82-fa02-411c-feb4-60165e82249b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17249                                             im ready\n",
       "10205                        im a human being ive got some\n",
       "16875                          ill say a little a possible\n",
       "16512                  hey what is this you got black soap\n",
       "965                                he doesnt speak english\n",
       "                               ...                        \n",
       "6797                                          two three go\n",
       "11892      of course now right away before i get any older\n",
       "17980    not like him is it to do a thing like that wit...\n",
       "17017                                          didnt i say\n",
       "7508     hello im paul carey from the airline im here t...\n",
       "Name: msg_pre_processed, Length: 13400, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17249    0\n",
       "10205    0\n",
       "16875    0\n",
       "16512    1\n",
       "965      0\n",
       "        ..\n",
       "6797     0\n",
       "11892    0\n",
       "17980    1\n",
       "17017    1\n",
       "7508     0\n",
       "Name: target, Length: 13400, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "6yg81Oaw-uxU"
   },
   "outputs": [],
   "source": [
    "# encode training data set\n",
    "X_train_token = tokenizer.texts_to_matrix(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0R3fS3_M1M8b",
    "outputId": "cfecb0b1-184a-4a95-f6a3-c86082ebfdd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6o_hnoSlyPCC",
    "outputId": "514222d8-da1b-4ccf-89d6-fc2220d2cdeb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13400, 9711)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_token.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "IfbFpgVb-uxY"
   },
   "outputs": [],
   "source": [
    "#set the number of rows of X_train\n",
    "num_rows, num_cols = X_train_token.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dDgioaKkoVss",
    "outputId": "3a81feed-6bdc-4663-e128-e36297f99efd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0', '1'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = set(df_small['target'])\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small['target'] = df_small['target'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "g-kOJzqlLpRh",
    "outputId": "c1671940-a155-40eb-8f58-779817ebdffe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg_pre_processed</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17249</th>\n",
       "      <td>im ready</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10205</th>\n",
       "      <td>im a human being ive got some</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16875</th>\n",
       "      <td>ill say a little a possible</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16512</th>\n",
       "      <td>hey what is this you got black soap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>he doesnt speak english</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         msg_pre_processed  target\n",
       "17249                             im ready       0\n",
       "10205        im a human being ive got some       0\n",
       "16875          ill say a little a possible       0\n",
       "16512  hey what is this you got black soap       1\n",
       "965                he doesnt speak english       0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for the best parameters"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def create_model(X, y, activation='relu', momentum=0.9, learn_rate=0.01, decay=1e-6,\n",
    "                 dropout_rate=0.5, weight_constraint=1, neurons=20, init='uniform',\n",
    "                 optimizer='SGD', nesterov=False, num_cols=10, pos_fix='',\n",
    "                 epochs=10, validation_split=0.3, batch_size=20):\n",
    "        \n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim=num_cols, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons/2, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    #model.summary()\n",
    "    \n",
    "    # Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
    "    sgd = SGD(lr=learn_rate, decay=decay, momentum=momentum, nesterov=nesterov)\n",
    "    model.compile(loss='BinaryCrossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "    callbacks = [EarlyStopping(monitor='val_accuracy', patience=3, verbose=0),\n",
    "                tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),]\n",
    "    \n",
    "    hist = model.fit(X, y, epochs=epochs, validation_split=validation_split, batch_size=batch_size, verbose=1, callbacks=callbacks)\n",
    "    \n",
    "    model_name = './models/chatbot_model_'+ pos_fix +'_.h5'\n",
    "    #model.save(model_name, hist)\n",
    "\n",
    "    print('model '+ model_name +' created')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "#cross-validation - cell not-used anymore\n",
    "\n",
    "#This seasch must to be done due an isse with Kears and GridSearch\n",
    "#    ERROR: can't pickle _thread.RLock objects\n",
    "\n",
    "\n",
    "params = {\n",
    "    'activation': ['relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],\n",
    "    'momentum': [0.5, 0.9],\n",
    "    'learn_rate': [0.0001, 0.001],\n",
    "    'dropout_rate': [0.5, 0.8],\n",
    "    'neurons': [210, 500],\n",
    "    'epochs': [210],\n",
    "    'batch_size': [20, 40, 60, 100],\n",
    "    'decay': [1e-6, 1e-5, 1e-4, 1e-3],\n",
    "    'nesterov': [False, True]\n",
    "    }\n",
    "\n",
    "keys = list(params)\n",
    "i = 0\n",
    "for values in itertools.product(*map(params.get, keys)):\n",
    "    print(dict(zip(keys, values)))\n",
    "    model = create_model(**dict(zip(keys, values)), X=X_train_token, y=df_small['target'], num_cols=num_cols, pos_fix=str(i))\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAc01igYZJfe"
   },
   "source": [
    "### Training the model with fixed parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xFgmGR9f-uxv",
    "outputId": "ec3c427f-69f9-48f2-f7b6-629d4f521c8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 20)                194240    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 194,461\n",
      "Trainable params: 194,461\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model - 3 layers. First layer 128 neurons, second layer 64 neurons and 3rd output layer contains number of neurons\n",
    "# equal to number of intents to predict output intent with softmax\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=num_cols, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.6 ms, sys: 0 ns, total: 15.6 ms\n",
      "Wall time: 13.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=False)\n",
    "model.compile(loss='BinaryCrossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DdnwUEvW-ux1",
    "outputId": "727d8923-cd40-4503-e88b-0999565761ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2019 - accuracy: 0.9037 - val_loss: 0.9735 - val_accuracy: 0.8077\n",
      "Epoch 2/500\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2026 - accuracy: 0.9058 - val_loss: 0.9799 - val_accuracy: 0.8077\n",
      "Epoch 3/500\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1984 - accuracy: 0.9066 - val_loss: 0.9146 - val_accuracy: 0.8042\n",
      "Epoch 4/500\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2088 - accuracy: 0.9004 - val_loss: 0.9213 - val_accuracy: 0.8082\n",
      "Epoch 5/500\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1987 - accuracy: 0.9064 - val_loss: 0.9555 - val_accuracy: 0.8082\n",
      "Epoch 6/500\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1887 - accuracy: 0.9103 - val_loss: 1.0278 - val_accuracy: 0.8095\n",
      "Epoch 7/500\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2073 - accuracy: 0.9005 - val_loss: 1.0092 - val_accuracy: 0.8062\n",
      "Epoch 8/500\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1960 - accuracy: 0.9046 - val_loss: 0.9642 - val_accuracy: 0.8092\n",
      "Epoch 9/500\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1889 - accuracy: 0.9077 - val_loss: 0.9802 - val_accuracy: 0.8067\n",
      "Epoch 10/500\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1981 - accuracy: 0.9023 - val_loss: 0.9846 - val_accuracy: 0.8070\n",
      "Epoch 11/500\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1920 - accuracy: 0.9087 - val_loss: 1.0309 - val_accuracy: 0.8032\n",
      "Epoch 12/500\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1883 - accuracy: 0.9083 - val_loss: 1.0325 - val_accuracy: 0.8090\n",
      "Epoch 13/500\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1993 - accuracy: 0.9037 - val_loss: 1.0842 - val_accuracy: 0.8087\n",
      "Epoch 14/500\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1972 - accuracy: 0.9034 - val_loss: 1.0659 - val_accuracy: 0.8060\n",
      "Epoch 15/500\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1906 - accuracy: 0.9037 - val_loss: 0.9796 - val_accuracy: 0.8022\n",
      "Epoch 16/500\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1934 - accuracy: 0.9053 - val_loss: 1.0870 - val_accuracy: 0.8002\n",
      "model created\n",
      "CPU times: user 1min 1s, sys: 7.88 s, total: 1min 9s\n",
      "Wall time: 34.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_accuracy', patience=10, verbose=0),\n",
    "                ModelCheckpoint(filepath='model.{val_accuracy:.2f}-{epoch:02d}.h5'),\n",
    "            ]\n",
    "\n",
    "#fitting and saving the model\n",
    "hist = model.fit(X_train_token, df_small['target'], epochs=500, validation_split=0.3, batch_size=20, verbose=1, callbacks=callbacks)\n",
    "#model.save('chatbot_model.h5', hist)\n",
    "\n",
    "print(\"model created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUj8MLGpGmpl"
   },
   "source": [
    "### Testing the prototipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = os.getcwd()\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f)) and 'model.' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyfiles.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.0.81-14.h5',\n",
       " 'model.0.81-13.h5',\n",
       " 'model.0.81-12.h5',\n",
       " 'model.0.81-10.h5',\n",
       " 'model.0.81-09.h5',\n",
       " 'model.0.81-08.h5',\n",
       " 'model.0.81-07.h5',\n",
       " 'model.0.81-06.h5',\n",
       " 'model.0.81-05.h5',\n",
       " 'model.0.81-04.h5',\n",
       " 'model.0.81-02.h5',\n",
       " 'model.0.81-01.h5',\n",
       " 'model.0.80-16.h5',\n",
       " 'model.0.80-15.h5',\n",
       " 'model.0.80-11.h5',\n",
       " 'model.0.80-03.h5']"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onlyfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.0.81-14.h5\n"
     ]
    }
   ],
   "source": [
    "print(onlyfiles[0])\n",
    "model = load_model(onlyfiles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def pre_processing_text(corpus):\n",
    "    #remove html tags\n",
    "    corpus = re.sub(r'<.*?>', '', str(corpus))\n",
    "    \n",
    "    #remove non-alphanumeric characters\n",
    "    corpus = re.sub(r'[^a-z A-Z 0-9 \\s]', '', str(corpus))\n",
    "    \n",
    "    #remove duplicated spaces\n",
    "    corpus = re.sub(r' +', ' ', str(corpus))\n",
    "    \n",
    "    #capitalization\n",
    "    corpus = corpus.lower()\n",
    "    \n",
    "    #tokenization\n",
    "    corpus = re.findall(r\"\\w+(?:'\\w+)?|[^\\w\\s]\", corpus)\n",
    "    \n",
    "    #lammatization\n",
    "    corpus = [lemmatizer.lemmatize(c) for c in corpus]\n",
    "    \n",
    "    #remove punctuation\n",
    "    corpus = [t for t in corpus if t not in string.punctuation]\n",
    "    \n",
    "    #remove stopwords\n",
    "    #it makes the model worst\n",
    "    #stopwords_ = stopwords.words(\"english\")\n",
    "    #corpus = [t for t in corpus if t not in stopwords_]\n",
    "    \n",
    "    corpus = ' '.join(corpus)\n",
    "\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_raw = 'I heard you are a good guy. Is it right?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = pre_processing_text(msg_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "id": "S1zQZgEu-ux7"
   },
   "outputs": [],
   "source": [
    "p = tokenizer.texts_to_matrix([msg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PQ3tlzOFvBqs",
    "outputId": "8bc89fcd-78b9-40c1-835a-2e0de5a21d16"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 9711)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "id": "ukmWl_6h-uyE"
   },
   "outputs": [],
   "source": [
    "res = model.predict(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vB5caYtk-uyJ",
    "outputId": "c029790d-5746-4119-ab0e-3f34c0d886f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99999243]], dtype=float32)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model\n",
    "- The model is overfited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode training data set\n",
    "X_test_token = tokenizer.texts_to_matrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_int = [int(y) for y in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6591084771965988"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test_int, y_pred.round())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "TF - Chatbot-protptipo-v2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
