{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-BSEigEE-utQ"
   },
   "source": [
    "## Esteira de similaridade de textos por Jaccard, Cosseno e Cosseno com Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AgR-ezT5-utZ",
    "outputId": "f773f454-e438-42fd-81a2-70b325be7745"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import re\n",
    "import gensim\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import load_model\n",
    "from scipy.spatial import distance\n",
    "import math\n",
    "import random\n",
    "import bz2\n",
    "import itertools\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expand jupyter cells\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Um5L0h0-utn"
   },
   "source": [
    "### Opening movie reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Crtu4lkNCvuE"
   },
   "outputs": [],
   "source": [
    "messages = pd.read_csv('./chatdata/movie_lines_pre_processed_for_test.tsv', delimiter=\"\\t\", header = None, quoting=3, encoding='ISO-8859-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.columns = ['msg_line', 'user_id', 'movie_id', 'msg', 'msg_pre_processed', 'msg_2', 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the list of questions and answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s0r76sH8-uy9"
   },
   "outputs": [],
   "source": [
    "questions = set(messages[messages['target'] == 1]['msg_pre_processed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = set(messages[messages['target'] == 0]['msg_pre_processed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def pre_processing_text(corpus):\n",
    "    #remove html tags\n",
    "    corpus = re.sub(r'<.*?>', '', str(corpus))\n",
    "    \n",
    "    #remove non-alphanumeric characters\n",
    "    corpus = re.sub(r'[^a-z A-Z 0-9 \\s]', '', str(corpus))\n",
    "    \n",
    "    #remove duplicated spaces\n",
    "    corpus = re.sub(r' +', ' ', str(corpus))\n",
    "    \n",
    "    #capitalization\n",
    "    corpus = corpus.lower()\n",
    "    \n",
    "    #tokenization\n",
    "    corpus = re.findall(r\"\\w+(?:'\\w+)?|[^\\w\\s]\", corpus)\n",
    "    \n",
    "    #lammatization\n",
    "    corpus = [lemmatizer.lemmatize(c, get_wordnet_pos(c)) for c in corpus]\n",
    "    \n",
    "    #remove punctuation\n",
    "    corpus = [t for t in corpus if t not in string.punctuation]\n",
    "    \n",
    "    #remove stopwords\n",
    "    #it makes the model worst\n",
    "    #stopwords_ = stopwords.words(\"english\")\n",
    "    #corpus = [t for t in corpus if t not in stopwords_]\n",
    "    \n",
    "    corpus = ' '.join(corpus)\n",
    "\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_raw = 'I heard you are a good guy. Is it right?'\n",
    "#msg_raw = 'yes i heard you all right 20000000 thats quite a lot isnt it'\n",
    "msg = pre_processing_text(msg_raw)\n",
    "print(msg)\n",
    "\n",
    "with open('./chatdata/tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "p = tokenizer.texts_to_matrix([msg])\n",
    "\n",
    "model = load_model('./chatdata/chatbot_model.h5')\n",
    "res = model.predict(p)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returning the conversation for the message using Jaccard Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(f1, f2):    \n",
    "    f1 = set(str(f1).split(' '))\n",
    "    f2 = set(str(f2).split(' '))\n",
    "    \n",
    "    intersecao = f1.intersection(f2)\n",
    "    uniao = f1.union(f2)\n",
    "    \n",
    "    return len(intersecao) / len(uniao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_conversation_by_jaccard(msg, res, questions, answers, threshold=None):\n",
    "    \"\"\"\n",
    "    Return a dictionary of message and similarity sorted by highter similarity\n",
    "    \"\"\"\n",
    "    if res >= 0.5:\n",
    "        msg_list = questions\n",
    "        similarity = [jaccard_similarity(msg, str(m)) for m in questions]        \n",
    "    else:\n",
    "        similarity = [jaccard_similarity(msg, str(m)) for m in answers]\n",
    "        msg_list = answers\n",
    "    \n",
    "    result = dict(zip(msg_list, similarity))\n",
    "    \n",
    "    return {k: v for k, v in sorted(result.items(), key=lambda item: item[1], reverse=True)}    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def return_conversation_by_jaccard(msg, res, questions, answers, threshold=None):\n",
    "    \"\"\"\n",
    "    Return a dictionary of message and similarity sorted by highter similarity\n",
    "    \"\"\"\n",
    "    if res >= 0.5:\n",
    "        msg_list = questions\n",
    "        similarity = [jaccard_similarity(msg, str(m)) for m in questions]        \n",
    "    else:\n",
    "        similarity = [jaccard_similarity(msg, str(m)) for m in answers]\n",
    "        msg_list = answers\n",
    "    \n",
    "    result = {} \n",
    "    for key in msg_list: \n",
    "        for value in similarity:\n",
    "            result[key] = value\n",
    "            similarity.remove(value) \n",
    "            break \n",
    "    \n",
    "    return {k: v for k, v in sorted(result.items(), key=lambda item: item[1], reverse=True)}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UUjgakfd-uzQ"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "conversations = return_conversation_by_jaccard(msg, res, questions, answers)\n",
    "conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the first item in the dict\n",
    "def get_the_next_conversation(conversations):\n",
    "    keys_view = conversations.keys()\n",
    "    keys_iterator = iter(keys_view)\n",
    "    conversation = next(keys_iterator)\n",
    "    return conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = get_the_next_conversation(conversations)\n",
    "conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The returned message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('>>> '+msg_raw)\n",
    "msg2 = list(messages[messages['msg_pre_processed'] == conversation]['msg_2'])[0]\n",
    "print('<<< '+msg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate PageRank\n",
    "- create a bi-directional graph of messages using similarity bigger then a threshould"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Classe para criação de um nó (página) do grafo.\n",
    "O cosntrutuor recebe recebe o nome do nó, a lista de nós de entrada e saída.\n",
    "\"\"\"\n",
    "class Node(object):\n",
    "    def __init__(self, node_name: str, inlinks: list, outlinks: list):\n",
    "        self.node_name = node_name\n",
    "        self.inlinks = inlinks\n",
    "        self.outlinks = outlinks\n",
    "\n",
    "\"\"\"\n",
    "Classe para criação do grafo de páginas.\n",
    "O construtor inicializa um dicionário vazio de lista de adjacência. \n",
    "\"\"\"\n",
    "class Graph(object):\n",
    "    def __init__(self):\n",
    "        self.adj_list = dict()\n",
    "\n",
    "    #Adiciona um nó ao grafo com seus nós de entrada e sapida\n",
    "    def add_node(self, node_name: str, inlinks: list, outlinks: list):\n",
    "        node = Node(node_name = node_name, inlinks=inlinks, outlinks=outlinks)\n",
    "        self.adj_list[node_name] = node\n",
    "\n",
    "    #Imprime os dados do grafo criado\n",
    "    def print_graph(self):\n",
    "        for key in self.adj_list:\n",
    "            print(f\"{key}:\")\n",
    "            print(f\"\\tEntrada: {self.adj_list[key].inlinks}\")\n",
    "            print(f\"\\tSaída: {self.adj_list[key].outlinks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "A classe PageRank possui métodos para computar o Page Rank de cada página dado um número de iterações.\n",
    "\"\"\"\n",
    "class PageRank(object):\n",
    "    #Construtor da classe que recebe um objeto Graph, inicializa um dicionário vazio de scores\n",
    "    def __init__(self, graph: Graph):\n",
    "        self.graph = graph\n",
    "        self.scores = dict()\n",
    "        self.__initialize_scores()\n",
    "\n",
    "    #Inicializa os scores do Page Rank com o valor inicial 1/n, onde n é o número de nós (páginas) do grafo\n",
    "    def __initialize_scores(self):\n",
    "        n = len(self.graph.adj_list)\n",
    "        for key in self.graph.adj_list:\n",
    "            self.scores[key] = 1/n\n",
    "\n",
    "    #Calcula o Page Rank para cada página dado o número de iterações. Ainda não utiliza a convergence_rate no cálculos\n",
    "    def compute(self, iterations: int = 10, convergence_rate: float = 0.01):\n",
    "        new_scores = dict()\n",
    "        for i in range(iterations):\n",
    "            for  node in self.graph.adj_list:\n",
    "                in_to_node = np.asarray([\n",
    "                    self.scores[x] for x in self.graph.adj_list[node].inlinks\n",
    "                ])\n",
    "                out_to_node = self.graph.adj_list[node].inlinks\n",
    "                amount_out_to_node = np.asarray([\n",
    "                    len(self.graph.adj_list[x].outlinks) for x in out_to_node\n",
    "                ])\n",
    "                score = np.sum(in_to_node / amount_out_to_node)\n",
    "                new_scores[node] = score\n",
    "            #print(self.scores)\n",
    "            self.scores = new_scores.copy()\n",
    "        return self.scores\n",
    "\n",
    "    def power_method(self, iterations: int = 10):\n",
    "        #Gera a matrix de probabilidades de navegação a cada nó\n",
    "        lenght = len(self.graph.adj_list)\n",
    "        matrix = np.zeros((lenght, lenght))\n",
    "        i = j = 0\n",
    "        for node in self.graph.adj_list:\n",
    "            for link in self.graph.adj_list[node].outlinks:\n",
    "                for row in self.graph.adj_list:\n",
    "                    if link == row:\n",
    "                        matrix[i][j] = 1/len(self.graph.adj_list[node].outlinks)\n",
    "                    i = i + 1\n",
    "                i = 0\n",
    "            j = j + 1\n",
    "        print(\"Matriz de probabilidades \")\n",
    "        print(matrix)\n",
    "        #muliplica a matrix pelo score inicial\n",
    "        print(\"Page Rank das iterações\")\n",
    "        scores_arr = np.asarray([\n",
    "                    self.scores[key] for key in self.graph.adj_list\n",
    "                ])\n",
    "        itn = np.dot(matrix, scores_arr)\n",
    "        print(itn)\n",
    "        for i in range(iterations - 1):\n",
    "            itn = np.dot(matrix, itn)\n",
    "            print(itn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_in_links(conversations, threshold=0.3):\n",
    "    li = list()\n",
    "    if threshold is None:\n",
    "        li = conversations.keys()\n",
    "    else:\n",
    "        dic = {k: v for k, v in conversations.items() if v >= threshold}\n",
    "        li = [c for c in dic.keys()]\n",
    "        \n",
    "    return li"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def make_in_links(conversations, threshold=0.3):\n",
    "    li = list()\n",
    "    if threshold is None:\n",
    "        for c in conversations.keys():\n",
    "            li.append(c)\n",
    "    else:\n",
    "        for c in conversations.keys():\n",
    "            if conversations[c] >= threshold:\n",
    "                li.append(c)\n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversations(msg, res):\n",
    "    return return_conversation_by_jaccard(msg, res, questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graph(qea, res, threshold=None):\n",
    "    g = Graph()\n",
    "    lenght = len(qea)\n",
    "    i = 1\n",
    "    \n",
    "    for k in qea:\n",
    "        conversations = get_conversations(k, res)\n",
    "        if conversations is not None:\n",
    "            in_links = make_in_links(conversations, threshold=threshold)\n",
    "            in_links.remove(k)\n",
    "            g.add_node(k, in_links, in_links)\n",
    "        if (i % 100) == 0:\n",
    "            print('Processed '+ str(i) +' of '+ str(lenght))    \n",
    "        i += 1\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_page_compute(qea, res, file_name, threshold=None, iterations=3):\n",
    "\n",
    "    g = make_graph(qea=qea, res=res, threshold=threshold)\n",
    "\n",
    "    p = PageRank(graph=g)\n",
    "    pc = p.compute(iterations=iterations)\n",
    "    pc = {k: v for k, v in sorted(pc.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "    f = open( './chatdata/' + file_name + '.txt', 'w' )\n",
    "    f.write( repr(pc) )\n",
    "    f.close()\n",
    "    return pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pc_q = save_page_compute(qea=questions, res=1, threshold=threshold, file_name='page_rank_questions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pc_a = save_page_compute(qea=answers, res=0, threshold=threshold, file_name='page_rank_answers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking page rank tends to 1\n",
    "s = 0\n",
    "#pc_q = pc_a\n",
    "for p in pc_q:\n",
    "    s += pc_q[p]\n",
    "    \n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similary of Jaccard based on Page Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_conversation_by_page_rank(msg, conversations, page_compute):\n",
    "    \"\"\"\n",
    "    Return a dictionary of message and similarity sorted by highter similarity\n",
    "    \"\"\"  \n",
    "    similarity = {k: v for k, v in conversations.items()}\n",
    "    \n",
    "    result = dict()\n",
    "    for k, v in similarity.items():        \n",
    "        result[k] = page_compute[k] * v\n",
    "    \n",
    "    result = {k: v for k, v in sorted(result.items(), key=lambda item: item[1], reverse=True)}\n",
    "    return next(iter(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = return_conversation_by_page_rank(msg, conversations, page_compute=pc_q)\n",
    "print('Conversation: '+ conversation)\n",
    "print('Page compute: '+ str(pc_q[conversation]))\n",
    "print('Similarity: '+ str(conversations[conversation]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original: '+ msg)\n",
    "print('Most similar: '+conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('>>> '+msg_raw)\n",
    "msg2 = list(messages[messages['msg_pre_processed'] == conversation]['msg_2'])[0]\n",
    "print('<<< '+msg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return the result using the Cossine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_conversation_by_cossine(msg, res, questions, answers, bow):\n",
    "    \"\"\"\n",
    "    Return a dictionary of message and similarity sorted by highter similarity\n",
    "    \"\"\"\n",
    "    if res >= 0.5:\n",
    "        msg_list = questions    \n",
    "    else:\n",
    "        msg_list = answers\n",
    "       \n",
    "    similarity = []\n",
    "    for m in msg_list:\n",
    "        new_msg_list = [msg, m]\n",
    "        vector_bow = bow.fit_transform(new_msg_list)\n",
    "        msg_bow = vector_bow.todense()[0]\n",
    "        m_bow   = vector_bow.todense()[1]\n",
    "        similarity.append(distance.cosine(msg_bow, m_bow))\n",
    "    \n",
    "    result = {} \n",
    "    for key in msg_list: \n",
    "        for value in similarity: \n",
    "            result[key] = value\n",
    "            similarity.remove(value) \n",
    "            break \n",
    "    \n",
    "    return {k: v for k, v in sorted(result.items(), key=lambda item: item[1], reverse=False)}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations = return_conversation_by_cossine(msg, res, questions, answers, bow)\n",
    "conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = get_the_next_conversation(conversations)\n",
    "conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('>>> '+msg_raw)\n",
    "msg2 = list(messages[messages['msg_pre_processed'] == conversation]['msg_2'])[0]\n",
    "print('<<< '+msg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = return_conversation_by_page_rank(msg, conversations, page_compute=pc_q)\n",
    "print('Conversation: '+ conversation)\n",
    "print('Page compute: '+ str(pc_q[conversation]))\n",
    "print('Similarity: '+ str(conversations[conversation]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('>>> '+msg_raw)\n",
    "msg2 = list(messages[messages['msg_pre_processed'] == conversation]['msg_2'])[0]\n",
    "print('<<< '+msg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get result using Cossine Similarity with Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_embedding(get_it):\n",
    "    if get_it:\n",
    "        !gdown https://drive.google.com/uc?id=1zI8pGfbUHuU_0wY_FV4tD6w6ZCUJTQbh\n",
    "    print('Download finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The embedding is already downloaded\n",
    "#Change to True to download\n",
    "download_embedding(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#get the embedding\n",
    "newfilepath = \"embedding_wiki_100d_pt.txt\"\n",
    "filepath = \"ptwiki_20180420_100d.txt.bz2\"\n",
    "with open(newfilepath, 'wb') as new_file, bz2.BZ2File(filepath, 'rb') as file:\n",
    "    for data in iter(lambda : file.read(100 * 1024), b''):\n",
    "        new_file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "word_vectors = gensim.models.KeyedVectors.load_word2vec_format(filepath, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_embedding(phrase):\n",
    "    \"\"\"\n",
    "    Return the mean of embeddings of a phrase\n",
    "    \"\"\"\n",
    "    \n",
    "    arr = np.array([word_vectors[word] for word in phrase if word in word_vectors.vocab])\n",
    "    \n",
    "    sum = np.zeros(len(arr[0]))\n",
    "    for a in arr:\n",
    "        sum = sum + a\n",
    "        \n",
    "    arr_mean = sum / len(arr) \n",
    "    \n",
    "    return arr_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_conversation_by_cossine_embedding(msg, res, questions, answers, word_vectors):\n",
    "    \"\"\"\n",
    "    Return a dictionary of message and similarity sorted by highter similarity\n",
    "    \"\"\"\n",
    "    if res >= 0.5:\n",
    "        msg_list = questions    \n",
    "    else:\n",
    "        msg_list = answers       \n",
    "    \n",
    "    msg = msg.split(' ')\n",
    "    \n",
    "    similarity = []\n",
    "    for m in msg_list:        \n",
    "        m = m.split(' ')\n",
    "        \n",
    "        try:\n",
    "            msg_vector_embedding = calculate_embedding(msg)\n",
    "            m_vector_embedding   = calculate_embedding(m)\n",
    "        \n",
    "            similarity.append(distance.cosine(msg_vector_embedding, m_vector_embedding))\n",
    "        except:\n",
    "            print(\"An exception occurred\")\n",
    "            print('> '+ ' '.join(m))\n",
    "    \n",
    "    result = {} \n",
    "    for key in msg_list: \n",
    "        for value in similarity: \n",
    "            result[key] = value\n",
    "            similarity.remove(value) \n",
    "            break \n",
    "    \n",
    "    return {k: v for k, v in sorted(result.items(), key=lambda item: item[1], reverse=False)}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "conversations = return_conversation_by_cossine_embedding(msg, res, questions, answers, word_vectors)\n",
    "conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = get_the_next_conversation(conversations)\n",
    "conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('>>> '+msg_raw)\n",
    "msg2 = list(messages[messages['msg_pre_processed'] == conversation]['msg_2'])[0]\n",
    "print('<<< '+msg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = return_conversation_by_page_rank(msg, conversations, page_compute=pc_q)\n",
    "print('Conversation: '+ conversation)\n",
    "print('Page compute: '+ str(pc_q[conversation]))\n",
    "print('Similarity: '+ str(conversations[conversation]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('>>> '+msg_raw)\n",
    "msg2 = list(messages[messages['msg_pre_processed'] == conversation]['msg_2'])[0]\n",
    "print('<<< '+msg2)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "TF - Chatbot-protptipo-v2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
