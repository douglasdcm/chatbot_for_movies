{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A intenção do projeto é criar um chatbot baseado em reviews de filmes para que se possa fazer perguntas e manter uma conversa livre\n",
    "\n",
    "- link do banco de dados https://www.kaggle.com/Cornell-University/movie-dialog-corpus?select=movie_lines.tsv\n",
    "- referências\n",
    ">- https://shanebarker.com/blog/deep-learning-chatbot/\n",
    "> -https://towardsdatascience.com/how-to-create-a-chatbot-with-python-deep-learning-in-less-than-an-hour-56a063bdfc44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import gensim\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting parameters for data visualization\n",
    "np.set_printoptions(threshold=None, precision=2)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('precision', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening movie reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = pd.read_csv('./chatdata/movie_lines_pre_processed.tsv', header = None, delimiter=\"\\t\", quoting=3, encoding='ISO-8859-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.columns = ['msg_line', 'user_id', 'movie_id', 'msg', 'msg_pre_processed', 'msg_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg_line</th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>msg</th>\n",
       "      <th>msg_pre_processed</th>\n",
       "      <th>msg_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L49</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>Did you change your hair?</td>\n",
       "      <td>did you change your hair?</td>\n",
       "      <td>no.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L50</td>\n",
       "      <td>u3</td>\n",
       "      <td>m0</td>\n",
       "      <td>No.</td>\n",
       "      <td>no.</td>\n",
       "      <td>you might wanna think about it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L51</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>You might wanna think about it</td>\n",
       "      <td>you might wanna think about it</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L59</td>\n",
       "      <td>u9</td>\n",
       "      <td>m0</td>\n",
       "      <td>I missed you.</td>\n",
       "      <td>i missed you.</td>\n",
       "      <td>it say here you exposed yourself to a group of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L60</td>\n",
       "      <td>u8</td>\n",
       "      <td>m0</td>\n",
       "      <td>It says here you exposed yourself to a group o...</td>\n",
       "      <td>it say here you exposed yourself to a group of...</td>\n",
       "      <td>it wa a bratwurst. i wa eating lunch.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>L61</td>\n",
       "      <td>u9</td>\n",
       "      <td>m0</td>\n",
       "      <td>It was a bratwurst.  I was eating lunch.</td>\n",
       "      <td>it wa a bratwurst. i wa eating lunch.</td>\n",
       "      <td>with the teeth of your zipper?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>L62</td>\n",
       "      <td>u8</td>\n",
       "      <td>m0</td>\n",
       "      <td>With the teeth of your zipper?</td>\n",
       "      <td>with the teeth of your zipper?</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>L63</td>\n",
       "      <td>u7</td>\n",
       "      <td>m0</td>\n",
       "      <td>You the new guy?</td>\n",
       "      <td>you the new guy?</td>\n",
       "      <td>so they tell me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>L64</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>So they tell me...</td>\n",
       "      <td>so they tell me...</td>\n",
       "      <td>c'mon. i'm supposed to give you the tour.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>L65</td>\n",
       "      <td>u7</td>\n",
       "      <td>m0</td>\n",
       "      <td>C'mon.  I'm supposed to give you the tour.</td>\n",
       "      <td>c'mon. i'm supposed to give you the tour.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  msg_line user_id movie_id  \\\n",
       "0      L49      u0       m0   \n",
       "1      L50      u3       m0   \n",
       "2      L51      u0       m0   \n",
       "3      L59      u9       m0   \n",
       "4      L60      u8       m0   \n",
       "5      L61      u9       m0   \n",
       "6      L62      u8       m0   \n",
       "7      L63      u7       m0   \n",
       "8      L64      u2       m0   \n",
       "9      L65      u7       m0   \n",
       "\n",
       "                                                 msg  \\\n",
       "0                          Did you change your hair?   \n",
       "1                                                No.   \n",
       "2                     You might wanna think about it   \n",
       "3                                      I missed you.   \n",
       "4  It says here you exposed yourself to a group o...   \n",
       "5           It was a bratwurst.  I was eating lunch.   \n",
       "6                     With the teeth of your zipper?   \n",
       "7                                   You the new guy?   \n",
       "8                                 So they tell me...   \n",
       "9         C'mon.  I'm supposed to give you the tour.   \n",
       "\n",
       "                                   msg_pre_processed  \\\n",
       "0                          did you change your hair?   \n",
       "1                                                no.   \n",
       "2                     you might wanna think about it   \n",
       "3                                      i missed you.   \n",
       "4  it say here you exposed yourself to a group of...   \n",
       "5              it wa a bratwurst. i wa eating lunch.   \n",
       "6                     with the teeth of your zipper?   \n",
       "7                                   you the new guy?   \n",
       "8                                 so they tell me...   \n",
       "9          c'mon. i'm supposed to give you the tour.   \n",
       "\n",
       "                                               msg_2  \n",
       "0                                                no.  \n",
       "1                     you might wanna think about it  \n",
       "2                                                  -  \n",
       "3  it say here you exposed yourself to a group of...  \n",
       "4              it wa a bratwurst. i wa eating lunch.  \n",
       "5                     with the teeth of your zipper?  \n",
       "6                                                  -  \n",
       "7                                 so they tell me...  \n",
       "8          c'mon. i'm supposed to give you the tour.  \n",
       "9                                                  -  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(messages, title=\"Pandas Profiling Report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 263010 entries, 0 to 263009\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   msg_line           263010 non-null  object\n",
      " 1   user_id            263010 non-null  object\n",
      " 2   movie_id           263010 non-null  object\n",
      " 3   msg                263010 non-null  object\n",
      " 4   msg_pre_processed  263009 non-null  object\n",
      " 5   msg_2              263007 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 12.0+ MB\n"
     ]
    }
   ],
   "source": [
    "messages.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg_line</th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>msg</th>\n",
       "      <th>msg_pre_processed</th>\n",
       "      <th>msg_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>263010</td>\n",
       "      <td>263010</td>\n",
       "      <td>263010</td>\n",
       "      <td>263010</td>\n",
       "      <td>263009</td>\n",
       "      <td>263007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>263010</td>\n",
       "      <td>9001</td>\n",
       "      <td>617</td>\n",
       "      <td>263010</td>\n",
       "      <td>263009</td>\n",
       "      <td>166057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>L665615</td>\n",
       "      <td>u3681</td>\n",
       "      <td>m289</td>\n",
       "      <td>This is my home.</td>\n",
       "      <td>and the second rule about it is... you're not ...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>442</td>\n",
       "      <td>1293</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>72648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       msg_line user_id movie_id               msg  \\\n",
       "count    263010  263010   263010            263010   \n",
       "unique   263010    9001      617            263010   \n",
       "top     L665615   u3681     m289  This is my home.   \n",
       "freq          1     442     1293                 1   \n",
       "\n",
       "                                        msg_pre_processed   msg_2  \n",
       "count                                              263009  263007  \n",
       "unique                                             263009  166057  \n",
       "top     and the second rule about it is... you're not ...       -  \n",
       "freq                                                    1   72648  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Analysis based on this article\n",
    "- https://neptune.ai/blog/exploratory-data-analysis-natural-language-processing-tools?utm_source=medium&utm_medium=crosspost&utm_campaign=blog-exploratory-data-analysis-natural-language-processing-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = messages['msg_pre_processed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of characters of each message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#histogram to display the number of character of each message\n",
    "data.str.len().hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of characters are between 0 and 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{float, str}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the average word length\n",
    "data_set = [type(item) for item in data]\n",
    "data_set = set(data_set)\n",
    "data_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print float values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "{nan}\n"
     ]
    }
   ],
   "source": [
    "float_val = [it for it in data if isinstance(it, float)]\n",
    "print(len(float_val))\n",
    "float_val = set(float_val)\n",
    "print(float_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing non-alphabetical messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example of sequence of null messages\n",
    "messages[538:540]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling the nan messages with a string\n",
    "messages = messages.fillna('UNKNOWN')\n",
    "data = messages['msg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of words for each message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of words for each message\n",
    "data.str.split(' ').\\\n",
    "    map(lambda x: len(str(x))).\\\n",
    "    hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of words are between 0 and 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the average word length\n",
    "data.str.split(' ').\\\n",
    "   apply(lambda x : [len(i) for i in x]). \\\n",
    "   map(lambda x: np.mean(x)).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The length of words goes from 0 to 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribuition of stopwords in the mesages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkig the distribuition of stopwrds in the mesages\n",
    "stop=set(stopwords.words('english'))\n",
    "corpus=[]\n",
    "msg_ = data.str.split()\n",
    "msg_ = msg_.values.tolist()\n",
    "corpus=[word for i in msg_ for word in i]\n",
    "\n",
    "from collections import defaultdict\n",
    "dic=defaultdict(int)\n",
    "for word in corpus:\n",
    "    if word in stop:\n",
    "        dic[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(dic.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dic.keys()\n",
    "y = dic.values()\n",
    "plt.subplots(figsize=(30,5))\n",
    "plt.bar(x, y, 1, color='b')\n",
    "plt.xticks(list(x), rotation=90, fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of stop words are 'to', 'you', 'the' and 'a'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Occurences of each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting the occurences of each word\n",
    "counter=Counter(corpus)\n",
    "most=counter.most_common()\n",
    "\n",
    "x, y= [], []\n",
    "for word,count in most[:40]:\n",
    "    if (word not in stop):\n",
    "        x.append(word)\n",
    "        y.append(count)\n",
    "        \n",
    "sns.barplot(x=y,y=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word 'I' has the biggest occurrence. There are a lot of messages like dashes that can be removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the most frequent n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the most frequent n-grams\n",
    "def get_top_ngram(corpus, n=None):\n",
    "    vec = CountVectorizer(ngram_range=(n, n)).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) \n",
    "                  for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_n_gram(corpus, n=2):\n",
    "    top_n_bigrams=get_top_ngram(corpus,n)[:10]\n",
    "    x,y=map(list,zip(*top_n_bigrams))\n",
    "    sns.barplot(x=y,y=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_n_gram(data, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more frequent bigram is 'you re'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_n_gram(data, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of short questions like 'what do you...?', 'what are you...?', and answers like 'you want to...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_n_gram(data, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of repeated questions and answers or part of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentimental analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkig the polarity of the messages\n",
    "def polarity(text):\n",
    "    return TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['polarity_score']=data.\\\n",
    "   apply(lambda x : polarity(x))\n",
    "messages['polarity_score'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of polarity is neutral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named entity recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TYPE\tDESCRIPTION\n",
    "- PERSON\tPeople, including fictional.\n",
    "- NORP\tNationalities or religious or political groups.\n",
    "- FAC\tBuildings, airports, highways, bridges, etc.\n",
    "- ORG\tCompanies, agencies, institutions, etc.\n",
    "- GPE\tCountries, cities, states.\n",
    "- LOC\tNon-GPE locations, mountain ranges, bodies of water.\n",
    "- PRODUCT\tObjects, vehicles, foods, etc. (Not services.)\n",
    "- EVENT\tNamed hurricanes, battles, wars, sports events, etc.\n",
    "- WORK_OF_ART\tTitles of books, songs, etc.\n",
    "- LAW\tNamed documents made into laws.\n",
    "- LANGUAGE\tAny named language.\n",
    "- DATE\tAbsolute or relative dates or periods.\n",
    "- TIME\tTimes smaller than a day.\n",
    "- PERCENT\tPercentage, including ”%“.\n",
    "- MONEY\tMonetary values, including unit.\n",
    "- QUANTITY\tMeasurements, as of weight or distance.\n",
    "- ORDINAL\t“first”, “second”, etc.\n",
    "- CARDINAL\tNumerals that do not fall under another type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the messages in a big document\n",
    "def get_entities(corpus, int_limit=0, end_limit=100):\n",
    "    msg_all = ' '.join(data[int_limit:end_limit])\n",
    "    doc = nlp(msg_all)\n",
    "\n",
    "    entity_list = [(x.text,x.label_) for x in doc.ents]\n",
    "    \n",
    "    return entity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ent_list = set()\n",
    "skip = 1000\n",
    "i = 0\n",
    "lim = len(data)\n",
    "#lim = 20000\n",
    "\n",
    "while(i < lim):    \n",
    "    ent_list = set(get_entities(data, i, i+skip))\n",
    "    ent_list.union(ent_list)\n",
    "    i = i + skip\n",
    "    print('Processed '+str(i)+' of '+str(lim)+' messages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ent_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some personal names, real locals, name of organizations and work of art that can be removed or replaced for generic terms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_df = pd.DataFrame(list(ent_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_df.to_csv('./chatdata/entity_list.tsv', index=False, sep='\\t', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner(text):\n",
    "    doc=nlp(text)\n",
    "    return [X.label_ for X in doc.ents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#count the number of each entity\n",
    "ent=data.\\\n",
    "    apply(lambda x : ner(x))\n",
    "ent=[x for sub in ent for x in sub]\n",
    "\n",
    "counter=Counter(ent)\n",
    "count=counter.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=map(list,zip(*count))\n",
    "sns.barplot(x=y,y=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most comon tokens per entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner(text,ent=\"PERSON\"):\n",
    "    doc=nlp(text)\n",
    "    return [X.text for X in doc.ents if X.label_ == ent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#count the tokens for a given entity type\n",
    "gpe=data.apply(lambda x: ner(x, 'PERSON'))\n",
    "gpe=[i for x in gpe for i in x]\n",
    "counter=Counter(gpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=map(list,zip(*counter.most_common(10)))\n",
    "sns.barplot(y,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parts of Speach Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are eight main parts of speech:\n",
    "\n",
    "- Noun (NN)- Joseph, London, table, cat, teacher, pen, city\n",
    "- Verb (VB)- read, speak, run, eat, play, live, walk, have, like, are, is\n",
    "- Adjective(JJ)- beautiful, happy, sad, young, fun, three\n",
    "- Adverb(RB)- slowly, quietly, very, always, never, too, well, tomorrow\n",
    "- Preposition (IN)- at, on, in, from, with, near, between, about, under\n",
    "- Conjunction (CC)- and, or, but, because, so, yet, unless, since, if\n",
    "- Pronoun(PRP)- I, you, we, they, he, she, it, me, us, them, him, her, this\n",
    "- Interjection (INT)- Ouch! Wow! Great! Help! Oh! Hey! Hi!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicated_spaces(corpus):\n",
    "    #remove duplicated spaces\n",
    "    corpus_alt = re.sub(r' +', ' ', corpus)\n",
    "\n",
    "    return corpus_alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_no_space = [remove_duplicated_spaces(str(m)) for m in data]\n",
    "msg_no_space = pd.Series(msg_no_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos(text):\n",
    "    #matched = re.match(r\" +\", text)\n",
    "    if text != ' ':\n",
    "        #print(text)\n",
    "        pos=nltk.pos_tag(word_tokenize(text))\n",
    "        #print(pos)\n",
    "        pos=list(map(list,zip(*pos)))[1]\n",
    "        return pos\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tags=msg_no_space[0:5000].apply(lambda x : pos(x))\n",
    "#tags = [pos(m) for m in msg_no_space[0:10000]]\n",
    "#tags\n",
    "tags=[x for l in tags for x in l]\n",
    "counter=Counter(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=list(map(list,zip(*counter.most_common(7))))\n",
    "sns.barplot(x=y,y=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### most commonly nouns\n",
    "def get_adjs(text, _tag='PRP'):\n",
    "    adj=[]\n",
    "    pos=nltk.pos_tag(word_tokenize(text))\n",
    "    for word,tag in pos:\n",
    "        if tag == _tag:\n",
    "            adj.append(word)\n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "words=msg.apply(lambda x : get_adjs(x))\n",
    "words=[x for l in words for x in l]\n",
    "counter=Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=list(map(list,zip(*counter.most_common(7))))\n",
    "sns.barplot(x=y,y=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text complexy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flesch Reading Ease (FRE)\n",
    "<br>Higher scores indicate material that is easier to read, lower numbers mark harder-to-read passages:\n",
    "- 0-30 College\n",
    "- 50-60 High school\n",
    "- 60+ Fourth grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textstat import flesch_reading_ease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "reading = msg.\\\n",
    "   apply(lambda x : flesch_reading_ease(x))\n",
    "reading.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text is easy to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[i for i in range(len(reading)) if reading[i]<0]\n",
    "\n",
    "messages.iloc[x]['msg'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
